{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from tempfile import TemporaryFile\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post processing our data\n",
    "from dateutil import parser\n",
    "\n",
    "final_df = pd.DataFrame([])\n",
    "\n",
    "date_list = ['2021-12-01','2021-12-02','2021-12-03','2021-12-04','2021-12-05','2021-12-06','2021-12-07']\n",
    "\n",
    "for date in date_list:\n",
    "    temp_df = pd.read_csv(f'data/Synthetic Site/Synthetic Site Predictors {date}.csv')\n",
    "    temp_output = pd.read_csv(f'data/Synthetic Site/Synthetic Site Targets {date}.csv')\n",
    "\n",
    "    temp_df['Timestamp'] = temp_df['Timestamp'].map(lambda x: parser.parse(x[0:-13]))\n",
    "\n",
    "    processed_df =  temp_df.iloc[:,1:].astype(float)\n",
    "    \n",
    "#     processed_df['year'] = temp_df['Timestamp'].map(lambda x: float(x.year))\n",
    "#     processed_df['month_of_yr'] =  temp_df['Timestamp'].map(lambda x: float(x.month))\n",
    "#     processed_df['day_of_yr'] =  temp_df['Timestamp'].map(lambda x: float(x.timetuple().tm_yday))\n",
    "#     processed_df['day_of_month'] =  temp_df['Timestamp'].map(lambda x: float(x.day))\n",
    "    processed_df['day_of_week'] =  temp_df['Timestamp'].map(lambda x: float(x.weekday()))\n",
    "    processed_df['weekend'] =  processed_df['day_of_week'].map(lambda x: float(x>4))\n",
    "    processed_df['hour'] =  temp_df['Timestamp'].map(lambda x: float(x.hour))\n",
    "    processed_df['minute'] =  temp_df['Timestamp'].map(lambda x: float(x.minute))\n",
    "\n",
    "    processed_df['usage'] =  temp_output['Synthetic Site Electricity Main Total Power'].astype(float)\n",
    "\n",
    "    final_df = pd.concat([final_df, processed_df], axis = 0)\n",
    "    \n",
    "final_df = final_df.dropna()\n",
    "final_df = final_df.reset_index(drop = True)\n",
    "\n",
    "final_df.to_csv('data/Synthetic Site_dataset_2.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "# building the S2S model\n",
    "class S2S_Model(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, use_cuda):\n",
    "        super(S2S_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        if self.cell_type not in ['rnn', 'gru', 'lstm']:\n",
    "            raise ValueError(self.cell_type, \" is not an appropriate cell type. Please select one of rnn, gru, or lstm.\")\n",
    "        if self.cell_type == 'rnn':\n",
    "            self.Ecell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.RNNCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'gru':\n",
    "            self.Ecell = nn.GRUCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.GRUCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'lstm':\n",
    "            self.Ecell = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.LSTMCell(1, self.hidden_size)\n",
    "\n",
    "        self.lin_usage = nn.Linear(self.hidden_size, 1)\n",
    "        self.use_cuda = use_cuda\n",
    "        self.init()\n",
    "\n",
    "    # function to intialize weight parameters. Refer to Saxe at al. paper that explains why to use orthogonal init weights\n",
    "    def init(self):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "                    init.constant_(p.data[self.hidden_size:2*self.hidden_size], 1.0)\n",
    "\n",
    "    def consume(self, x):\n",
    "        # encoder forward function\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            h = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h = h.cuda()\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "            pred_usage = self.lin_usage(h)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            h0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            c0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h0 = h0.cuda()\n",
    "                c0 = c0.cuda()\n",
    "            h = (h0, c0)\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "            pred_usage = self.lin_usage(h[0])\n",
    "        return pred_usage, h\n",
    "\n",
    "    def predict(self, pred_usage, h, target_length):\n",
    "        # decoder forward function\n",
    "        preds = []\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                pred_usage = self.lin_usage(h)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                pred_usage = self.lin_usage(h[0])\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        return preds\n",
    "\n",
    "#########################################################################################\n",
    "# Bahdanau Attention model\n",
    "# refer to : AuCson github code\n",
    "# building the model\n",
    "class S2S_BA_Model(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, use_cuda):\n",
    "        super(S2S_BA_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_cuda = use_cuda\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        if self.cell_type not in ['rnn', 'gru', 'lstm']:\n",
    "            raise ValueError(self.cell_type, \" is not an appropriate cell type. Please select one of rnn, gru, or lstm.\")\n",
    "        if self.cell_type == 'rnn':\n",
    "            self.Ecell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.RNNCell(1+self.hidden_size, self.hidden_size)\n",
    "        if self.cell_type == 'gru':\n",
    "            self.Ecell = nn.GRUCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.GRUCell(1+self.hidden_size, self.hidden_size)\n",
    "        if self.cell_type == 'lstm':\n",
    "            self.Ecell = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.LSTMCell(1+self.hidden_size, self.hidden_size)\n",
    "\n",
    "        self.Wattn_energies = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.Wusage = nn.Linear(self.hidden_size, 1)\n",
    "        self.Wout = nn.Linear(1+self.hidden_size*2, self.hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(self.hidden_size))\n",
    "        stdv = 1./math.sqrt(self.v.size(0))\n",
    "        self.v.data.normal_(mean=0, std=stdv)\n",
    "        self.init()\n",
    "\n",
    "# function to intialize weight parameters\n",
    "    def init(self):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "                    init.constant_(p.data[self.hidden_size:2*self.hidden_size], 1.0)\n",
    "\n",
    "    def consume(self, x):\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            # encoder forward function\n",
    "            h = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h = h.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            # encoder part\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h\n",
    "            pred_usage = self.Wusage(h)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            h0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            c0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h0 = h0.cuda()\n",
    "                c0 = c0.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            h = (h0, c0)\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h[0]\n",
    "            pred_usage = self.Wusage(h[0])\n",
    "        return pred_usage, h, encoder_outputs\n",
    "\n",
    "    def predict(self, pred_usage, h, encoder_outputs, target_length):\n",
    "        # decoder with attention function\n",
    "        preds = []\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for step in range(target_length):\n",
    "                h_copies = h.expand(encoder_outputs.shape[0], -1, -1)\n",
    "                energies = torch.tanh(self.Wattn_energies(torch.cat((h_copies, encoder_outputs), 2)))\n",
    "                score = torch.sum(self.v * energies, dim=2)\n",
    "                attn_weights = score.t()\n",
    "                attn_weights = torch.softmax(attn_weights, dim=1).unsqueeze(1)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1)).squeeze(1)\n",
    "                gru_input = torch.cat((pred_usage, context), 1)\n",
    "                h = self.Dcell(gru_input, h)\n",
    "                output = self.Wout(torch.cat((pred_usage, h, context), 1))\n",
    "                pred_usage = self.Wusage(output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for step in range(target_length):\n",
    "                h_copies = h[0].expand(encoder_outputs.shape[0], -1, -1)\n",
    "                energies = torch.tanh(self.Wattn_energies(torch.cat((h_copies, encoder_outputs), 2)))\n",
    "                score = torch.sum(self.v * energies, dim=2)\n",
    "                attn_weights = score.t()\n",
    "                attn_weights = torch.softmax(attn_weights, dim=1).unsqueeze(1)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1)).squeeze(1)\n",
    "                gru_input = torch.cat((pred_usage, context), 1)\n",
    "                h = self.Dcell(gru_input, h)\n",
    "                output = self.Wout(torch.cat((pred_usage, h[0], context), 1))\n",
    "                pred_usage = self.Wusage(output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        return preds\n",
    "\n",
    "#############################################################################################3\n",
    "# Luong Attention module\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        \n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \" is not an appropriate attention method, please select one of dot, general, or concat.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        if self.method == 'concat':\n",
    "            self.attn = nn.Linear(2*self.hidden_size, self.hidden_size)\n",
    "            self.v = nn.Parameter(torch.rand(self.hidden_size))\n",
    "            stdv = 1./math.sqrt(self.v.size(0))\n",
    "            self.v.data.normal_(mean=0, std=stdv)\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        attn_energies = torch.sum(hidden*encoder_output, dim=2)\n",
    "        return attn_energies\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        attn_energies = torch.sum(hidden*energy, dim=2)\n",
    "        return attn_energies\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden.expand(encoder_output.shape[0], -1, -1),\n",
    "                            encoder_output), 2)))\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    # calculate the attention weights (energies) based on the given method\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        if self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        attn_energies = attn_energies.t()\n",
    "        attn_weights = torch.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "        return attn_weights\n",
    "\n",
    "#########################################################################################\n",
    "#  building the S2S LA model\n",
    "class S2S_LA_Model(nn.Module):\n",
    "    def __init__(self, cell_type, attn_method, input_size, hidden_size, use_cuda):\n",
    "        super(S2S_LA_Model, self).__init__()\n",
    "        self.cell_type = cell_type\n",
    "        self.attn_method = attn_method\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.cell_type == 'rnn':\n",
    "            self.Ecell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.RNNCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'gru':\n",
    "            self.Ecell = nn.GRUCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.GRUCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'lstm':\n",
    "            self.Ecell = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.LSTMCell(1, self.hidden_size)\n",
    "\n",
    "        self.lin_usage = nn.Linear(hidden_size, 1)\n",
    "        self.lin_concat = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.attn = Attn(self.attn_method, self.hidden_size)\n",
    "        self.use_cuda = use_cuda\n",
    "        self.init()\n",
    "\n",
    "    # function to intialize weight parameters\n",
    "    def init(self):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "                    init.constant_(p.data[self.hidden_size:2*self.hidden_size], 1.0)\n",
    "\n",
    "    def consume(self, x):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            # encoder forward function\n",
    "            h = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h = h.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            # encoder part\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h\n",
    "            pred_usage = self.lin_usage(h)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            h0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            c0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h0 = h0.cuda()\n",
    "                c0 = c0.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            h = (h0, c0)\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h[0]\n",
    "            pred_usage = self.lin_usage(h[0])\n",
    "        return pred_usage, h, encoder_outputs\n",
    "\n",
    "    def predict(self, pred_usage, h, encoder_outputs, target_length):\n",
    "        # decoder with attention function\n",
    "        preds = []\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                attn_weights = self.attn(h, encoder_outputs)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "                context = context.squeeze(1)\n",
    "                concat_input = torch.cat((h, context), 1)\n",
    "                concat_output = torch.tanh(self.lin_concat(concat_input))\n",
    "                pred_usage = self.lin_usage(concat_output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                attn_weights = self.attn(h[0], encoder_outputs)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "                context = context.squeeze(1)\n",
    "                concat_input = torch.cat((h[0], context), 1)\n",
    "                concat_output = torch.tanh(self.lin_concat(concat_input))\n",
    "                pred_usage = self.lin_usage(concat_output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        return preds\n",
    "\n",
    "#################################################################################################################################################\n",
    "# main function\n",
    "def main(seed, cuda, cell_type, attention_model, la_method, window_source_size,\n",
    "            window_target_size, epochs, batch_size, hs, save_model):\n",
    "    t0 = time.time()\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(\"Loading dataset...\")\n",
    "#     d = np.loadtxt(\"data/Synthetic Site_dataset_2.csv\", delimiter=\",\", skiprows=1, dtype=float)\n",
    "#     # removing unneeded columns\n",
    "#     dataset = d[:, 1:].astype(np.float32)\n",
    "#     dataset = pd.DataFrame(dataset)\n",
    "#     dataset.columns = ['month_of_yr', 'day_of_yr','day_of_month', 'season','day_of_week', 'weekend', 'holiday', 'hour', 'minute', 'temp', 'hum', 'usage']\n",
    "# #     dataset = pd.read_csv(\"data/Synthetic Site_dataset.csv\")\n",
    "# #     dataset = dataset.astype(np.float32)\n",
    "#     # switch around columns\n",
    "# #     dataset = dataset[['month_of_yr', 'day_of_yr','day_of_month', 'season',\n",
    "# #              'day_of_week', 'weekend', 'holiday', 'hour', 'minute', 'temp', 'hum', 'usage']]\n",
    "#     dataset = dataset[['month_of_yr', 'day_of_yr','temp', 'hum', 'usage']]\n",
    "# #     dataset = dataset.drop('minute',1).drop('temp',1).drop('hum',1)\n",
    "\n",
    "    dataset = pd.read_csv(\"data/Synthetic Site_dataset_2.csv\").astype(np.float32)\n",
    "    usage_actual = dataset['usage']\n",
    "    mu_usage = dataset['usage'].mean()\n",
    "    std_usage = dataset['usage'].std()\n",
    "    dataset = dataset.values\n",
    "\n",
    "    # 0 mean and unit var\n",
    "    print(\"Transforming data to 0 mean and unit var\")\n",
    "    MU = dataset.mean(0) # 0 means take the mean of the column\n",
    "    dataset = dataset - MU\n",
    "    STD = dataset.std(0) # same with std here\n",
    "    dataset = dataset / STD\n",
    "\n",
    "    # 5 minutes between rows.\n",
    "    # use 1 hour (12 rows) to predict next half hour (6 rows)\n",
    "    print(\"Generating training and test data...\")\n",
    "    WINDOW_SOURCE_SIZE = window_source_size\n",
    "    WINDOW_TARGET_SIZE = window_target_size\n",
    "\n",
    "    # getting actual usage vector, aligning with predicted values vector. Aka remove first window_source_size and remaining\n",
    "    usage_actual = usage_actual.values\n",
    "    usage_actual = usage_actual[int(dataset.shape[0]*0.80):]\n",
    "    usage_actual = usage_actual[WINDOW_SOURCE_SIZE:]\n",
    "\n",
    "    # 80% train, 20% test\n",
    "    train_source = dataset[:int(dataset.shape[0]*0.80)]\n",
    "    test_source = dataset[int(dataset.shape[0]*0.80):]\n",
    "\n",
    "    # if N = data.shape[0] - (WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE)\n",
    "    # then you will be sliding over every one\n",
    "\n",
    "    def generate_windows(data):\n",
    "        x_train = []\n",
    "        y_usage_train = []\n",
    "        x_test = []\n",
    "        y_usage_test = []\n",
    "\n",
    "        # for training data\n",
    "        idxs = np.random.choice(train_source.shape[0]-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), train_source.shape[0]-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), replace=False)\n",
    "\n",
    "        for idx in idxs:\n",
    "            x_train.append(train_source[idx:idx+WINDOW_SOURCE_SIZE].reshape((1, WINDOW_SOURCE_SIZE, train_source.shape[1])) )\n",
    "            y_usage_train.append(train_source[idx+WINDOW_SOURCE_SIZE:idx+WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE, -1].reshape((1, WINDOW_TARGET_SIZE, 1)) )\n",
    "\n",
    "        x_train = np.concatenate(x_train, axis=0) # make them arrays and not lists\n",
    "        y_usage_train = np.concatenate(y_usage_train, axis=0)\n",
    "\n",
    "        # for testing data\n",
    "        idxs = np.arange(0, len(test_source)-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), WINDOW_TARGET_SIZE)\n",
    "\n",
    "        for idx in idxs:\n",
    "            x_test.append(test_source[idx:idx+WINDOW_SOURCE_SIZE].reshape((1, WINDOW_SOURCE_SIZE, test_source.shape[1])) )\n",
    "            y_usage_test.append(test_source[idx+WINDOW_SOURCE_SIZE:idx+WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE, -1].reshape((1, WINDOW_TARGET_SIZE, 1)) )\n",
    "\n",
    "        x_test = np.concatenate(x_test, axis=0) # make them arrays and not lists\n",
    "        y_usage_test = np.concatenate(y_usage_test, axis=0)\n",
    "\n",
    "        return x_train, y_usage_train, x_test, y_usage_test\n",
    "\n",
    "    X_train, Y_train_usage, X_test, Y_test_usage = generate_windows(dataset)\n",
    "    print(\"Created {} train samples and {} test samples\".format(X_train.shape[0], X_test.shape[0]))\n",
    "    idxs = np.arange(0, len(test_source)-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), WINDOW_TARGET_SIZE)\n",
    "    remainder = len(test_source) - (idxs[-1] + WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE)\n",
    "    usage_actual = usage_actual[:-remainder]\n",
    "\n",
    "#################################################################################################################################################\n",
    "# call the model\n",
    "    #print(\"Creating model...\")\n",
    "    INPUT_SIZE = X_train.shape[-1]\n",
    "    HIDDEN_SIZE = hs\n",
    "    CELL_TYPE = cell_type\n",
    "    LA_METHOD = la_method\n",
    "\n",
    "    # call the respective model\n",
    "    if attention_model == 'none':\n",
    "        model = S2S_Model(CELL_TYPE, INPUT_SIZE, HIDDEN_SIZE, use_cuda=cuda)\n",
    "\n",
    "    elif attention_model == 'BA':\n",
    "        model = S2S_BA_Model(CELL_TYPE, INPUT_SIZE, HIDDEN_SIZE, use_cuda=cuda)\n",
    "\n",
    "    elif attention_model == 'LA':\n",
    "        model = S2S_LA_Model(CELL_TYPE, LA_METHOD, INPUT_SIZE, HIDDEN_SIZE, use_cuda=cuda)\n",
    "\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        model.cuda()\n",
    "\n",
    "    print(\"MODEL ARCHITECTURE IS: \")\n",
    "    print(model)\n",
    "\n",
    "    print(\"\\nModel parameters are on cuda: {}\".format(next(model.parameters()).is_cuda))\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss(reduction='sum')\n",
    "    EPOCHES = epochs\n",
    "    BATCH_SIZE = batch_size\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    for epoch in range(EPOCHES):\n",
    "        t_one_epoch = time.time()\n",
    "        print(\"Epoch {}\".format(epoch+1))\n",
    "        total_usage_loss = 0\n",
    "        for b_idx in range(0, X_train.shape[0], BATCH_SIZE):\n",
    "\n",
    "            x = torch.from_numpy(X_train[b_idx:b_idx+BATCH_SIZE]).float()\n",
    "            y_usage = torch.from_numpy(Y_train_usage[b_idx:b_idx+BATCH_SIZE]).float()\n",
    "\n",
    "            if cuda:\n",
    "                x = x.cuda()\n",
    "                y_usage = y_usage.cuda()\n",
    "\n",
    "            # encoder forward, for respective models (with and without attention)\n",
    "            if attention_model == 'none':\n",
    "                pred_usage, h = model.consume(x)\n",
    "\n",
    "            elif attention_model == 'BA':\n",
    "                pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "            elif attention_model == 'LA':\n",
    "                pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "            # decoder forward, for respective models\n",
    "            if attention_model == 'none':\n",
    "                preds = model.predict(pred_usage, h, WINDOW_TARGET_SIZE)\n",
    "\n",
    "            elif attention_model == 'BA':\n",
    "                preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "            elif attention_model == 'LA':\n",
    "                preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "            # compute lose\n",
    "            loss_usage = loss_fn(preds, y_usage)\n",
    "\n",
    "            # backprop and update\n",
    "            opt.zero_grad()\n",
    "\n",
    "            loss_usage.backward()\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "            total_usage_loss += loss_usage.item()\n",
    "            \n",
    "        train_loss.append(total_usage_loss)\n",
    "        print(\"\\tTRAINING: {} total train USAGE loss.\\n\".format(total_usage_loss))\n",
    "\n",
    "#################################################################################################################################################\n",
    "# TESTING\n",
    "        y_usage = None\n",
    "        pred_usage = None\n",
    "        preds = None\n",
    "        total_usage_loss = 0\n",
    "        all_preds = []\n",
    "\n",
    "        for b_idx in range(0, X_test.shape[0], BATCH_SIZE):\n",
    "            with torch.no_grad():\n",
    "                x = torch.from_numpy(X_test[b_idx:b_idx+BATCH_SIZE])\n",
    "                y_usage = torch.from_numpy(Y_test_usage[b_idx:b_idx+BATCH_SIZE])\n",
    "\n",
    "                if cuda:\n",
    "                    x = x.cuda()\n",
    "                    y_usage = y_usage.cuda()\n",
    "\n",
    "                # encoder forward, for respective models\n",
    "                if attention_model == 'none':\n",
    "                    pred_usage, h = model.consume(x)\n",
    "\n",
    "                elif attention_model == 'BA':\n",
    "                    pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "                elif attention_model == 'LA':\n",
    "                    pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "                # decoder forward, for respective models\n",
    "                if attention_model == 'none':\n",
    "                    preds = model.predict(pred_usage, h, WINDOW_TARGET_SIZE)\n",
    "\n",
    "                elif attention_model == 'BA':\n",
    "                    preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "                elif attention_model == 'LA':\n",
    "                    preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "                # compute loss\n",
    "                loss_usage = loss_fn(preds, y_usage)\n",
    "\n",
    "                total_usage_loss += loss_usage.item()\n",
    "\n",
    "                if (epoch == epochs-1):\n",
    "                    all_preds.append(preds)\n",
    "\n",
    "        test_loss.append(total_usage_loss)\n",
    "\n",
    "        print(\"\\tTESTING: {} total test USAGE loss\".format(total_usage_loss))\n",
    "        print(\"\\tTESTING:\\n\")\n",
    "        print(\"\\tSample of prediction:\")\n",
    "        print(\"\\t\\t TARGET: {}\".format(y_usage[-1].cpu().detach().numpy().flatten()))\n",
    "        print(\"\\t\\t   PRED: {}\\n\\n\".format(preds[-1].cpu().detach().numpy().flatten()))\n",
    "\n",
    "        y_last_usage = y_usage[-1].cpu().detach().numpy().flatten()\n",
    "        pred_last_usage = preds[-1].cpu().detach().numpy().flatten()\n",
    "        t2_one_epoch = time.time()\n",
    "        time_one_epoch = t2_one_epoch - t_one_epoch\n",
    "        print(\"TIME OF ONE EPOCH: {} seconds and {} minutes\".format(time_one_epoch, time_one_epoch/60.0))\n",
    "\n",
    "####################################################################################################\n",
    "# SAVING MODEL\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"MODEL_w:__seed={}_cell_type={}_attention_model={}_la_method={}_T={}_N={}_bs={}_hs={}\".format(\n",
    "            seed, cell_type, attention_model, la_method,\n",
    "            window_source_size, window_target_size, batch_size, hs))\n",
    "\n",
    "#################################################################################################################################################\n",
    "# PLOTTING\n",
    "    # for plotting and accuracy\n",
    "    preds = torch.cat(all_preds, 0)\n",
    "    preds = preds.cpu().detach().numpy().flatten()\n",
    "    actual = Y_test_usage.flatten()\n",
    "\n",
    "    # for loss plotting\n",
    "    train_loss_array = np.asarray(train_loss)\n",
    "    test_loss_array = np.asarray(test_loss)\n",
    "    len_loss = np.arange(len(train_loss_array))\n",
    "\n",
    "    # unnormalizing 1\n",
    "    preds_unnorm = (preds*std_usage) + mu_usage\n",
    "\n",
    "    # using the actual usage from top of script here\n",
    "    mae3 = (sum(abs(usage_actual - preds_unnorm)))/(len(usage_actual))\n",
    "    mape3 = (sum(abs((usage_actual - preds_unnorm)/usage_actual)))/(len(usage_actual))\n",
    "\n",
    "    # for std\n",
    "    mape_s = (abs((usage_actual - preds_unnorm)/usage_actual))\n",
    "    s = mape_s.std()\n",
    "    mae_s = abs(usage_actual - preds_unnorm)\n",
    "    s2 = mae_s.std()\n",
    "    print(\"\\n\\tACTUAL ACC. RESULTS: MAE, MAPE: {} and {}%\".format(mae3, mape3*100.0))\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(1)\n",
    "    plt.plot(np.arange(len(preds)), preds, 'b', label='Predicted')\n",
    "    plt.plot(np.arange(len(actual)), actual, 'g', label='Actual')\n",
    "    plt.title(\"Predicted vs Actual, {} timesteps to {} timesteps\".format(window_source_size, window_target_size))\n",
    "    plt.xlabel(\"Time in 5 minute increments\")\n",
    "    plt.ylabel(\"Usage (normalized)\")\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "#     plt.figure(2)\n",
    "#     plt.plot(np.arange(len(actual)), actual, 'g', label='Actual')\n",
    "#     plt.plot(np.arange(len(preds)), preds, 'b', label='Predicted')\n",
    "#     plt.title(\"Predicted vs Actual, {} timesteps to {} timesteps\".format(window_source_size, window_target_size))\n",
    "#     plt.xlabel(\"Time in 5 minute increments\")\n",
    "#     plt.ylabel(\"Usage (normalized)\")\n",
    "#     plt.legend(loc='lower left')\n",
    "\n",
    "#     plt.figure(3)\n",
    "#     plt.plot(np.arange(len(y_last_usage)), y_last_usage, 'g', label='Actual')\n",
    "#     plt.plot(np.arange(len(pred_last_usage)), pred_last_usage, 'b', label='Predicted')\n",
    "#     plt.title(\"Predicted vs Actual last test example, {} timesteps to {} timesteps\".format(window_source_size, window_target_size))\n",
    "#     plt.xlabel(\"Time in 5 minute increments\")\n",
    "#     plt.ylabel(\"Usage (normalized)\")\n",
    "#     plt.legend(loc='lower left')\n",
    "\n",
    "#     plt.figure(4)\n",
    "#     plt.plot(np.arange(len(usage_actual[-12*24*7:])), usage_actual[-12*24*7:], 'g', label='Actual')\n",
    "#     plt.plot(np.arange(len(preds_unnorm[-12*24*7:])), preds_unnorm[-12*24*7:], 'b', label='Predicted')\n",
    "#     plt.title(\"Predicted vs Actual: Case 2, Zoom last 7 days\".format(window_source_size, window_target_size))\n",
    "#     plt.xlabel(\"Time in 5 minute increments\")\n",
    "#     plt.ylabel(\"Usage (kW)\")\n",
    "#     plt.legend(loc='lower left')\n",
    "\n",
    "#     plt.figure(5)\n",
    "#     plt.plot(len_loss, train_loss_array, 'k')\n",
    "#     plt.title(\"Train loss\")\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "\n",
    "#     plt.figure(6)\n",
    "#     plt.plot(len_loss, test_loss_array, 'r')\n",
    "#     plt.title(\"Test Loss\")\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "\n",
    "    # total time of run\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(\"\\nTIME ELAPSED: {} seconds OR {} minutes\".format(total, total/60.0))\n",
    "    print(\"\\nEnd of run\")\n",
    "    plt.show()\n",
    "    for_plotting = [usage_actual, preds_unnorm, y_last_usage, pred_last_usage]\n",
    "    return s, s2, mape_s, mae_s, mae3, mape3, total/60.0, train_loss, test_loss, for_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Transforming data to 0 mean and unit var\n",
      "Generating training and test data...\n",
      "Created 8042 train samples and 333 test samples\n",
      "MODEL ARCHITECTURE IS: \n",
      "S2S_BA_Model(\n",
      "  (Ecell): LSTMCell(12, 64)\n",
      "  (Dcell): LSTMCell(65, 64)\n",
      "  (Wattn_energies): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (Wusage): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (Wout): Linear(in_features=129, out_features=64, bias=True)\n",
      ")\n",
      "\n",
      "Model parameters are on cuda: True\n",
      "\n",
      "Starting training...\n",
      "Epoch 1\n",
      "\tTRAINING: 16491.279846191406 total train USAGE loss.\n",
      "\n",
      "\tTESTING: 566.5044422149658 total test USAGE loss\n",
      "\tTESTING:\n",
      "\n",
      "\tSample of prediction:\n",
      "\t\t TARGET: [ 0.0791177  -0.0031497  -0.04903844 -0.07976366 -0.10483488 -0.11744238]\n",
      "\t\t   PRED: [0.19033816 0.11567306 0.10172602 0.08471853 0.07042702 0.05816173]\n",
      "\n",
      "\n",
      "TIME OF ONE EPOCH: 1.1166927814483643 seconds and 0.01861154635747274 minutes\n",
      "Epoch 2\n",
      "\tTRAINING: 11371.650970458984 total train USAGE loss.\n",
      "\n",
      "\tTESTING: 540.8630867004395 total test USAGE loss\n",
      "\tTESTING:\n",
      "\n",
      "\tSample of prediction:\n",
      "\t\t TARGET: [ 0.0791177  -0.0031497  -0.04903844 -0.07976366 -0.10483488 -0.11744238]\n",
      "\t\t   PRED: [-0.01668488 -0.07243648 -0.09140682 -0.10912581 -0.12329113 -0.13474406]\n",
      "\n",
      "\n",
      "TIME OF ONE EPOCH: 0.8193461894989014 seconds and 0.013655769824981689 minutes\n",
      "\n",
      "\tACTUAL ACC. RESULTS: MAE, MAPE: 4.231566179980029 and 6.877016558379862%\n",
      "\n",
      "TIME ELAPSED: 2.024048328399658 seconds OR 0.03373413880666097 minutes\n",
      "\n",
      "End of run\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    s, s2, mape_s, mae_s, mae, mape, total_mins, train_loss, test_loss, for_plotting = main(seed=0, cuda=True,\n",
    "        cell_type='lstm', attention_model='BA', la_method='none',\n",
    "        window_source_size=12, window_target_size=6, epochs=2,\n",
    "        batch_size=256, hs=64, save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
