{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_DIRECTORY = C:\\Users\\JKIM4\\Anaconda3\\envs\\wattile\\Lib\\site-packages\\wattile\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from dateutil import parser\n",
    "from pathlib import Path\n",
    "import json \n",
    "import shutil\n",
    "import logging\n",
    "import copy\n",
    "logger = logging.getLogger(str(os.getpid()))\n",
    "\n",
    "from wattile.data_reading import read_dataset_from_file\n",
    "from wattile.buildings_processing import _resample_data, correct_predictor_columns, correct_timestamps, resample_or_rolling_stats, timelag_predictors, timelag_predictors_target, roll_predictors_target, input_data_split, prep_for_rnn, _preprocess_data\n",
    "from wattile.time_processing import add_processed_time_columns\n",
    "from wattile.models import ModelFactory\n",
    "from wattile.entry_point import init_logging, create_input_dataframe, run_model\n",
    "PROJECT_DIRECTORY = Path().resolve().parent.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_input': {'data_dir': 'C:\\\\Users\\\\JKIM4\\\\Documents\\\\GitHub\\\\intelligentcampus-pred-analytics\\\\tests\\\\data\\\\Synthetic Site',\n",
       "  'data_config': 'Synthetic Site Config.json',\n",
       "  'start_time': '2018-01-01T00:00:00-07:00',\n",
       "  'end_time': '2022-01-01T00:00:00-07:00',\n",
       "  'predictor_columns': ['Synthetic Weather Station Dew Point Temperature',\n",
       "   'Synthetic Weather Station Diffuse Horizontal Irradiance',\n",
       "   'Synthetic Weather Station Direct Normal Irradiance',\n",
       "   'Synthetic Weather Station Dry Bulb Temperature',\n",
       "   'Synthetic Weather Station Global Horizontal Irradiance',\n",
       "   'Synthetic Weather Station Relative Humidity',\n",
       "   'Synthetic Weather Station Wind Speed'],\n",
       "  'target_var': 'Synthetic Site Electricity Main Total Power'},\n",
       " 'data_output': {'exp_dir': 'C:\\\\Users\\\\JKIM4\\\\Documents\\\\GitHub\\\\intelligentcampus-pred-analytics\\\\notebooks\\\\exp_dir1',\n",
       "  'plot_comparison': True,\n",
       "  'plot_comparison_portion_start': 0.0,\n",
       "  'plot_comparison_portion_end': 1.0},\n",
       " 'data_processing': {'feat_time': {'month_of_year': ['sincos'],\n",
       "   'day_of_week': ['binary_reg', 'binary_fuzzy'],\n",
       "   'hour_of_day': ['sincos', 'binary_reg', 'binary_fuzzy'],\n",
       "   'holidays': False},\n",
       "  'resample': {'bin_interval': '15min',\n",
       "   'bin_closed': 'right',\n",
       "   'bin_label': 'right'},\n",
       "  'feat_stats': {'active': True, 'window_width': '15min'},\n",
       "  'feat_timelag': {'lag_interval': '15min', 'lag_count': 24},\n",
       "  'input_output_window': {'window_width_source': '180min',\n",
       "   'window_width_futurecast': '0min',\n",
       "   'window_width_target': '45min'},\n",
       "  'random_seed': 382,\n",
       "  'sequential_splicer': {'active': False, 'window_width': '1W'},\n",
       "  'data_split': '80:20:0',\n",
       "  'train_size_factor': 1},\n",
       " 'learning_algorithm': {'arch_type': 'RNN',\n",
       "  'arch_version': 'alfa',\n",
       "  'arch_type_variant': 'lstm',\n",
       "  'use_case': 'train',\n",
       "  'num_epochs': 100,\n",
       "  'hidden_size': 25,\n",
       "  'num_layers': 1,\n",
       "  'quantiles': [0.025, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.975],\n",
       "  'transformation_method': 'minmaxscale',\n",
       "  'train_batch_size': 26,\n",
       "  'val_batch_size': 1,\n",
       "  'run_resume': False,\n",
       "  'optimizer_config': {'weight_decay': 0.001,\n",
       "   'base': 0.001,\n",
       "   'schedule': False,\n",
       "   'type': 'performance',\n",
       "   'factor': 0.1,\n",
       "   'min': 1e-05,\n",
       "   'patience': 30,\n",
       "   'step_size': 75},\n",
       "  'smoothing_alpha': 0.001,\n",
       "  'eval_frequency': 500,\n",
       "  'test_method': 'external'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For this example, we will be using the default configs.\n",
    "Check out the docs for an explaination of each config.\n",
    "\"\"\"\n",
    "# main configs file\n",
    "with open(PROJECT_DIRECTORY / \"wattile\" / \"configs\" / \"configs.json\", \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "\n",
    "exp_dir = PROJECT_DIRECTORY / \"notebooks\" / \"exp_dir1\"\n",
    "if exp_dir.exists():\n",
    "    shutil.rmtree(exp_dir)\n",
    "exp_dir.mkdir()\n",
    "\n",
    "configs[\"data_output\"][\"exp_dir\"] = str(exp_dir)\n",
    "configs[\"data_input\"][\"data_dir\"] = str(PROJECT_DIRECTORY / \"tests\" / \"data\" / \"Synthetic Site\")\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update configs if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_input': {'data_dir': 'C:\\\\Users\\\\JKIM4\\\\Documents\\\\GitHub\\\\intelligentcampus-pred-analytics\\\\tests\\\\data\\\\Synthetic Site',\n",
       "  'data_config': 'Synthetic Site Config.json',\n",
       "  'start_time': '2018-01-01T00:00:00-07:00',\n",
       "  'end_time': '2022-01-01T00:00:00-07:00',\n",
       "  'predictor_columns': ['Synthetic Weather Station Dew Point Temperature',\n",
       "   'Synthetic Weather Station Diffuse Horizontal Irradiance',\n",
       "   'Synthetic Weather Station Direct Normal Irradiance',\n",
       "   'Synthetic Weather Station Dry Bulb Temperature',\n",
       "   'Synthetic Weather Station Global Horizontal Irradiance',\n",
       "   'Synthetic Weather Station Relative Humidity',\n",
       "   'Synthetic Weather Station Wind Speed'],\n",
       "  'target_var': 'Synthetic Site Electricity Main Total Power'},\n",
       " 'data_output': {'exp_dir': 'C:\\\\Users\\\\JKIM4\\\\Documents\\\\GitHub\\\\intelligentcampus-pred-analytics\\\\notebooks\\\\exp_dir1',\n",
       "  'plot_comparison': True,\n",
       "  'plot_comparison_portion_start': 0.0,\n",
       "  'plot_comparison_portion_end': 1.0},\n",
       " 'data_processing': {'feat_time': {'month_of_year': ['sincos'],\n",
       "   'day_of_week': ['binary_reg', 'binary_fuzzy'],\n",
       "   'hour_of_day': ['sincos', 'binary_reg', 'binary_fuzzy'],\n",
       "   'holidays': False},\n",
       "  'resample': {'bin_interval': '15min',\n",
       "   'bin_closed': 'right',\n",
       "   'bin_label': 'left'},\n",
       "  'feat_stats': {'active': True, 'window_width': '15min'},\n",
       "  'feat_timelag': {'lag_interval': '15min', 'lag_count': 24},\n",
       "  'input_output_window': {'window_width_source': '180min',\n",
       "   'window_width_futurecast': '0min',\n",
       "   'window_width_target': '45min'},\n",
       "  'random_seed': 382,\n",
       "  'sequential_splicer': {'active': False, 'window_width': '1W'},\n",
       "  'data_split': '80:20:0',\n",
       "  'train_size_factor': 1},\n",
       " 'learning_algorithm': {'arch_type': 'RNN',\n",
       "  'arch_version': 'alfa',\n",
       "  'arch_type_variant': 'lstm',\n",
       "  'use_case': 'train',\n",
       "  'num_epochs': 100,\n",
       "  'hidden_size': 25,\n",
       "  'num_layers': 1,\n",
       "  'quantiles': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
       "  'transformation_method': 'minmaxscale',\n",
       "  'train_batch_size': 26,\n",
       "  'val_batch_size': 1,\n",
       "  'run_resume': False,\n",
       "  'optimizer_config': {'weight_decay': 0.001,\n",
       "   'base': 0.001,\n",
       "   'schedule': False,\n",
       "   'type': 'performance',\n",
       "   'factor': 0.1,\n",
       "   'min': 1e-05,\n",
       "   'patience': 30,\n",
       "   'step_size': 75},\n",
       "  'smoothing_alpha': 0.001,\n",
       "  'eval_frequency': 500,\n",
       "  'test_method': 'external'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs[\"learning_algorithm\"][\"quantiles\"] = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "configs[\"data_processing\"][\"resample\"][\"bin_closed\"] = \"right\"\n",
    "configs[\"data_processing\"][\"resample\"][\"bin_label\"] = \"left\"\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# methods to update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_or_rolling_stats(data, configs):\n",
    "\n",
    "    # reading configuration parameters.\n",
    "    # default is right labeled and right-closed window.\n",
    "    # window_position is hard coded for now.\n",
    "    # default is right-closed and backward-looking window.\n",
    "    bin_interval = configs[\"data_processing\"][\"resample\"][\"bin_interval\"]\n",
    "    bin_closed = configs[\"data_processing\"][\"resample\"][\"bin_closed\"]    \n",
    "    bin_label = configs[\"data_processing\"][\"resample\"][\"bin_label\"]\n",
    "    window_width = configs[\"data_processing\"][\"feat_stats\"][\"window_width\"]\n",
    "    window_position = \"backward\"  # forward, center, backward\n",
    "\n",
    "    if configs[\"data_processing\"][\"feat_stats\"][\"active\"]:\n",
    "\n",
    "        # seperate predictors and target\n",
    "        target = data[configs[\"data_input\"][\"target_var\"]]\n",
    "        X_data = data.drop(configs[\"data_input\"][\"target_var\"], axis=1)\n",
    "\n",
    "        # resampling for each statistics separately\n",
    "        data_resampler = X_data.resample(\n",
    "            rule=bin_interval, closed=bin_closed, label=bin_label\n",
    "        )\n",
    "        data_resample_min = data_resampler.min().add_suffix(\"_min\")\n",
    "        data_resample_max = data_resampler.max().add_suffix(\"_max\")\n",
    "        data_resample_sum = data_resampler.sum().add_suffix(\"_sum\")\n",
    "        data_resample_count = data_resampler.count().add_suffix(\"_count\")\n",
    "        \n",
    "        ##############################################################################\n",
    "        #TEMPORARY\n",
    "        ##############################################################################\n",
    "        data_resample_min.loc[:,data_resample_min.columns.str.contains(\"Synthetic Weather Station Dry Bulb Temperature_min\")].to_csv(\"./output1_after_resample.csv\")\n",
    "#         for index, entry in enumerate(data_resampler):\n",
    "#             print(\"entry {} = {}\".format(index, entry))\n",
    "\n",
    "        # setting configuration settings depending on window_position and bin_closed\n",
    "        if window_position == \"backward\":\n",
    "            arg_center = False\n",
    "        elif window_position == \"center\":\n",
    "            arg_center = True\n",
    "        elif window_position == \"forward\":\n",
    "            arg_center = False\n",
    "            data_resample_min = data_resample_min[::-1]\n",
    "            data_resample_max = data_resample_max[::-1]\n",
    "            data_resample_sum = data_resample_sum[::-1]\n",
    "            data_resample_count = data_resample_count[::-1]\n",
    "            if bin_closed == \"left\":\n",
    "                bin_closed = \"right\"\n",
    "            elif bin_closed == \"right\":\n",
    "                bin_closed = \"left\"\n",
    "\n",
    "        # adding rolling window statistics: minimum\n",
    "        mins = data_resample_min.rolling(\n",
    "            window=window_width,\n",
    "            min_periods=1,\n",
    "            center=arg_center,\n",
    "            closed=bin_closed,\n",
    "        ).min()\n",
    "\n",
    "        # adding rolling window statistics: maximum\n",
    "        maxs = data_resample_max.rolling(\n",
    "            window=window_width,\n",
    "            min_periods=1,\n",
    "            center=arg_center,\n",
    "            closed=bin_closed,     \n",
    "        ).max()\n",
    "\n",
    "        # adding rolling window statistics: sum\n",
    "        sums = data_resample_sum.rolling(\n",
    "            window=window_width,\n",
    "            min_periods=1,\n",
    "            center=arg_center,\n",
    "            closed=bin_closed,\n",
    "        ).sum()\n",
    "\n",
    "        # adding rolling window statistics: count\n",
    "        counts = data_resample_count.rolling(\n",
    "            window=window_width,\n",
    "            min_periods=1,\n",
    "            center=arg_center,\n",
    "            closed=bin_closed,\n",
    "        ).sum()  # this has to be sum for proper count calculation\n",
    "\n",
    "        # adding rolling window statistics: mean\n",
    "        means = sums.copy()\n",
    "        means.columns = means.columns.str.replace(\"_sum\", \"_mean\")\n",
    "        np.seterr(invalid=\"ignore\")  # supress/hide the warning\n",
    "        means.loc[:, :] = sums.values / counts.values\n",
    "\n",
    "        # combining min and max stats\n",
    "        data = pd.concat([mins, maxs, means], axis=1)\n",
    "        \n",
    "        ##############################################################################\n",
    "        # TEMPORARY\n",
    "        ##############################################################################\n",
    "        mins.loc[:,mins.columns.str.contains(\"Synthetic Weather Station Dry Bulb Temperature_min\")].to_csv(\"./output2_after_reample_rolling.csv\")\n",
    "        data.to_csv(\"./output3_after_resample_rolling_completeset.csv\")\n",
    "\n",
    "        # reordering dataframe based on window_position\n",
    "        if window_position == \"forward\":\n",
    "            data = data[::-1]\n",
    "\n",
    "        # adding resampled target back to the dataframe\n",
    "        target = _resample_data(target, configs)\n",
    "        data[configs[\"data_input\"][\"target_var\"]] = target\n",
    "\n",
    "    else:\n",
    "\n",
    "        # resample data\n",
    "        data = _resample_data(data, configs)\n",
    "        \n",
    "#     print(\"### data after resample_or_rolling_stats = {}\".format(data))\n",
    "\n",
    "    return data\n",
    "\n",
    "def timelag_predictors(data, configs):\n",
    "    \"\"\"\n",
    "    Create lagged versions of predictor variables in a DataFrame.\n",
    "    Used specifically for alfa learning methods.\n",
    "    :param data: (DataFrame)\n",
    "    :param configs: (Dict)\n",
    "    :return: (DataFrame)\n",
    "    \"\"\"\n",
    "\n",
    "    # reading configuration parameters\n",
    "    lag_interval = configs[\"data_processing\"][\"feat_timelag\"][\"lag_interval\"]\n",
    "    lag_count = configs[\"data_processing\"][\"feat_timelag\"][\"lag_count\"]\n",
    "    window_width_futurecast = configs[\"data_processing\"][\"input_output_window\"][\n",
    "        \"window_width_futurecast\"\n",
    "    ]\n",
    "    target_var = configs[\"data_input\"][\"target_var\"]\n",
    "\n",
    "    # splitting predictors and target\n",
    "    target = data[target_var]\n",
    "    data = data.drop(target_var, axis=1)\n",
    "    data_orig = data\n",
    "\n",
    "    # padding predictors\n",
    "    temp_holder = list()\n",
    "    temp_holder.append(data_orig)\n",
    "    for i in range(1, lag_count + 1):\n",
    "        shifted = (\n",
    "            data_orig.shift(freq=i * lag_interval)\n",
    "            .astype(\"float32\")\n",
    "            .add_suffix(\"_lag{}\".format(i))\n",
    "        )\n",
    "        temp_holder.append(shifted)\n",
    "    temp_holder.reverse()\n",
    "    data = pd.concat(temp_holder, axis=1)\n",
    "\n",
    "    if configs[\"learning_algorithm\"][\"use_case\"] != \"prediction\":\n",
    "        data[target_var] = target.shift(freq=\"-\" + window_width_futurecast)\n",
    "    else:\n",
    "        data[target_var] = 0  # dummy\n",
    "        ##############################################################################\n",
    "        #TEMPORARY\n",
    "        ##############################################################################\n",
    "        temp = copy.deepcopy(data)\n",
    "        temp = temp.loc[:, temp.columns.str.contains(\"Synthetic Weather Station Dry Bulb Temperature_min\")]\n",
    "        temp.to_csv(\"./output5.csv\")\n",
    "\n",
    "    data = data.dropna(how=\"any\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def _preprocess_data(configs, data):\n",
    "    \"\"\"Preprocess data as dictated by the configs.\n",
    "    :param configs: configs\n",
    "    :type configs: dict\n",
    "    :param data: data\n",
    "    :type data: pd.dataframe\n",
    "    :return: data\n",
    "    :rtype: pd.dataframe\n",
    "    \"\"\"\n",
    "    # assert we have the correct columns and order them\n",
    "    data = correct_predictor_columns(configs, data)\n",
    "\n",
    "    # sort and trim data specified time period\n",
    "    data = correct_timestamps(configs, data)\n",
    "\n",
    "    # Add time-based features\n",
    "    data = add_processed_time_columns(data, configs)\n",
    "    \n",
    "    ##############################################################################\n",
    "    #TEMPORARY\n",
    "    ##############################################################################\n",
    "    data.loc[:,data.columns.str.contains(\"Synthetic Weather Station Dry Bulb Temperature\")].to_csv(\"./output0_before_resample_rolling.csv\")\n",
    "\n",
    "    # Add statistics features\n",
    "    data = resample_or_rolling_stats(data, configs)\n",
    "    \n",
    "    ##############################################################################\n",
    "    #TEMPORARY\n",
    "    ##############################################################################\n",
    "    data.loc[:,data.columns.str.contains(\"Synthetic Weather Station Dry Bulb Temperature_min\")].to_csv(\"./output4.csv\")\n",
    "\n",
    "    # Add lag features\n",
    "    configs[\"input_dim\"] = data.shape[1] - 1\n",
    "    logger.info(\"Number of features: {}\".format(configs[\"input_dim\"]))\n",
    "    logger.debug(\"Features: {}\".format(data.columns.values))\n",
    "\n",
    "    if configs[\"learning_algorithm\"][\"arch_version\"] == \"alfa\":\n",
    "        data = timelag_predictors(data, configs)\n",
    "    elif configs[\"learning_algorithm\"][\"arch_version\"] == \"bravo\":\n",
    "        data = timelag_predictors_target(data, configs)\n",
    "    elif configs[\"learning_algorithm\"][\"arch_version\"] == \"charlie\":\n",
    "        data = roll_predictors_target(data, configs)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_window_for_output_time(datetime):\n",
    "    \"\"\"Given the time for which we want to predict, return the time window of the required\n",
    "    input.\n",
    "    :param output_time: the time for which we want to predict\n",
    "    :type output_time: datatime\n",
    "    :return: earliest time input should include, latest time input should include.\n",
    "    :rtype: dt.datetime, datetime\n",
    "    \"\"\"\n",
    "\n",
    "    # set prediction time with pandas timedelta\n",
    "    timestamp_cast = pd.to_datetime(datetime)  # current time needs to go in here\n",
    "\n",
    "    # set parameters\n",
    "    config_data_processing = configs[\"data_processing\"]\n",
    "    lag_interval = config_data_processing[\"feat_timelag\"][\"lag_interval\"]\n",
    "    lag_count = config_data_processing[\"feat_timelag\"][\"lag_count\"]\n",
    "    bin_interval = config_data_processing[\"resample\"][\"bin_interval\"]\n",
    "    bin_label = config_data_processing[\"resample\"][\"bin_label\"]\n",
    "\n",
    "    # calculating offsets\n",
    "    window_offset = pd.Timedelta(lag_interval) * lag_count\n",
    "\n",
    "    # calculating start and end time windows for input data\n",
    "#     if bin_label == \"left\":\n",
    "#         prediction_window_start_time = timestamp_cast - window_offset + pd.Timedelta(bin_interval)\n",
    "#         prediction_window_end_time = timestamp_cast + pd.Timedelta(bin_interval)\n",
    "#     elif bin_label == \"right\":\n",
    "    prediction_window_start_time = timestamp_cast - window_offset\n",
    "    prediction_window_end_time = timestamp_cast\n",
    "\n",
    "    return prediction_window_start_time, prediction_window_end_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to: C:\\Users\\JKIM4\\Documents\\GitHub\\intelligentcampus-pred-analytics\\notebooks\\exp_dir1\\output.out, PID: 5856\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# create results folder\n",
    "init_logging(local_results_dir=configs[\"data_output\"][\"exp_dir\"])\n",
    "\n",
    "################################################################\n",
    "# read data\n",
    "\n",
    "# data source 1\n",
    "# data = read_dataset_from_file(configs)\n",
    "\n",
    "# data source 2\n",
    "data = pd.read_csv(\"../../tests/fixtures/data_edge_consideration.csv\", index_col=0)\n",
    "\n",
    "# ################################################################\n",
    "# # prepare data for training\n",
    "# # train_df, val_df = prep_for_rnn(configs, data)\n",
    "\n",
    "# data = _preprocess_data(configs, data)\n",
    "\n",
    "# # if validatate with external data, write data to h5 for future testing.\n",
    "# if (\n",
    "#     configs[\"learning_algorithm\"][\"use_case\"] == \"validation\"\n",
    "#     and configs[\"learning_algorithm\"][\"test_method\"] == \"external\"\n",
    "# ):\n",
    "#     filepath = pathlib.Path(\n",
    "#         configs[\"data_input\"][\"data_dir\"]\n",
    "#     ) / \"{}_external_test.h5\".format(configs[\"data_input\"][\"target_var\"])\n",
    "#     data.to_hdf(filepath, key=\"df\", mode=\"w\")\n",
    "\n",
    "# if configs[\"learning_algorithm\"][\"use_case\"] == \"train\":\n",
    "#     train_df, val_df = input_data_split(data, configs)\n",
    "\n",
    "# else:\n",
    "#     train_df, val_df = pd.DataFrame(), data\n",
    "\n",
    "# ################################################################\n",
    "# # create model\n",
    "# model = ModelFactory.create_model(configs)\n",
    "\n",
    "# ################################################################\n",
    "# # train model\n",
    "# results = model.train(train_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model config with use case prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[\"learning_algorithm\"][\"use_case\"] = \"prediction\"\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = ModelFactory.create_model(configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determine read time span for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_casting = \"2021-12-07 07:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_window_start_time, prediction_window_end_time = model.get_input_window_for_output_time(time_casting)\n",
    "input_start, input_end = get_input_window_for_output_time(time_casting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = read_dataset_from_file(configs)\n",
    "data = data[input_start:input_end]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust model config start/end times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs['data_input']['start_time'] = input_start.isoformat()\n",
    "configs['data_input']['end_time'] = input_end.isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_grid = data\n",
    "# predictor_data_frame = predictor_grid.to_dataframe()\n",
    "# predictor_data_frame = predictor_data_frame.set_index('ts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[configs['data_input']['target_var']] = -999\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare data for training\n",
    "# train_df, val_df = prep_for_rnn(configs, data)\n",
    "\n",
    "data = _preprocess_data(configs, data)\n",
    "\n",
    "# if validatate with external data, write data to h5 for future testing.\n",
    "if (\n",
    "    configs[\"learning_algorithm\"][\"use_case\"] == \"validation\"\n",
    "    and configs[\"learning_algorithm\"][\"test_method\"] == \"external\"\n",
    "):\n",
    "    filepath = pathlib.Path(\n",
    "        configs[\"data_input\"][\"data_dir\"]\n",
    "    ) / \"{}_external_test.h5\".format(configs[\"data_input\"][\"target_var\"])\n",
    "    data.to_hdf(filepath, key=\"df\", mode=\"w\")\n",
    "\n",
    "if configs[\"learning_algorithm\"][\"use_case\"] == \"train\":\n",
    "    train_df, val_df = input_data_split(data, configs)\n",
    "\n",
    "else:\n",
    "    train_df, val_df = pd.DataFrame(), data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict with (trained) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model.predict(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wattile",
   "language": "python",
   "name": "wattile"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
