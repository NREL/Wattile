{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from tempfile import TemporaryFile\n",
    "from dateutil import parser\n",
    "import datetime as dt\n",
    "\n",
    "from intelcamp.data_reading import read_dataset_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post processing our data\n",
    "from dateutil import parser\n",
    "\n",
    "final_df = pd.DataFrame([])\n",
    "\n",
    "date_list = ['2021-12-01','2021-12-02','2021-12-03','2021-12-04','2021-12-05','2021-12-06','2021-12-07']\n",
    "\n",
    "for date in date_list:\n",
    "    temp_df = pd.read_csv(f'data/Synthetic Site/Synthetic Site Predictors {date}.csv')\n",
    "    temp_output = pd.read_csv(f'data/Synthetic Site/Synthetic Site Targets {date}.csv')\n",
    "    \n",
    "    temp_df['Timestamp'] = temp_df['Timestamp'].map(lambda x: parser.parse(x[0:-13]))\n",
    "\n",
    "    processed_df =  temp_df.iloc[:,1:].astype(float)\n",
    "    \n",
    "#     processed_df['year'] = temp_df['Timestamp'].map(lambda x: float(x.year))\n",
    "#     processed_df['month_of_yr'] =  temp_df['Timestamp'].map(lambda x: float(x.month))\n",
    "#     processed_df['day_of_yr'] =  temp_df['Timestamp'].map(lambda x: float(x.timetuple().tm_yday))\n",
    "#     processed_df['day_of_month'] =  temp_df['Timestamp'].map(lambda x: float(x.day))\n",
    "    processed_df['day_of_week'] =  temp_df['Timestamp'].map(lambda x: float(x.weekday()))\n",
    "    processed_df['weekend'] =  processed_df['day_of_week'].map(lambda x: float(x>4))\n",
    "    processed_df['hour'] =  temp_df['Timestamp'].map(lambda x: float(x.hour))\n",
    "    processed_df['minute'] =  temp_df['Timestamp'].map(lambda x: float(x.minute))\n",
    "\n",
    "    processed_df['usage'] =  temp_output['Synthetic Site Electricity Main Total Power'].astype(float)\n",
    "\n",
    "    final_df = pd.concat([final_df, processed_df], axis = 0)\n",
    "    \n",
    "final_df = final_df.dropna()\n",
    "final_df = final_df.reset_index(drop = True)\n",
    "\n",
    "final_df.to_csv('data/Synthetic Site_dataset_2.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "configs = {\n",
    "    \"use_case\": \"train\",\n",
    "    \n",
    "    \"data_dir\": \"../tests/data\",\n",
    "    \"building\": \"Synthetic Site\",\n",
    "    \"start_time\": \"2021-12-01T00:00:00-07:00\",\n",
    "    \"end_time\": \"2022-12-08T00:00:00-07:00\",\n",
    "    \n",
    "    \"predictor_columns\": [\n",
    "        \"SRRL BMS Dew Point Temperature\",\n",
    "        \"SRRL BMS Diffuse Horizontal Irradiance\",\n",
    "        \"SRRL BMS Direct Normal Irradiance\",\n",
    "        \"SRRL BMS Dry Bulb Temperature\",\n",
    "        \"SRRL BMS Global Horizontal Irradiance\",\n",
    "        \"SRRL BMS Relative Humidity\",\n",
    "        \"SRRL BMS Wind Speed at 19'\"\n",
    "    ],\n",
    "    \"target_var\": \"Synthetic Site Electricity Main Total Power\",\n",
    "}\n",
    "\n",
    "# read in dataset\n",
    "dataset = read_dataset_from_file(configs)\n",
    "\n",
    "# add in time info\n",
    "dataset['day_of_week'] =  dataset.index.map(lambda x: float(x.weekday()))\n",
    "dataset['weekend'] =  dataset['day_of_week'].map(lambda x: float(x>4))\n",
    "dataset['hour'] =  dataset.index.map(lambda x: float(x.hour))\n",
    "dataset['minute'] =  dataset.index.map(lambda x: float(x.minute))\n",
    "\n",
    "# name target \"usage\"\n",
    "target_var = dataset[configs[\"target_var\"]]\n",
    "dataset[\"usage\"] = target_var\n",
    "\n",
    "# remove timestamp index\n",
    "dataset = dataset.reset_index(drop = True)\n",
    "\n",
    "# drop nans\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "# building the S2S model\n",
    "class S2S_Model(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, use_cuda):\n",
    "        super(S2S_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        if self.cell_type not in ['rnn', 'gru', 'lstm']:\n",
    "            raise ValueError(self.cell_type, \" is not an appropriate cell type. Please select one of rnn, gru, or lstm.\")\n",
    "        if self.cell_type == 'rnn':\n",
    "            self.Ecell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.RNNCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'gru':\n",
    "            self.Ecell = nn.GRUCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.GRUCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'lstm':\n",
    "            self.Ecell = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.LSTMCell(1, self.hidden_size)\n",
    "\n",
    "        self.lin_usage = nn.Linear(self.hidden_size, 1)\n",
    "        self.use_cuda = use_cuda\n",
    "        self.init()\n",
    "\n",
    "    # function to intialize weight parameters. Refer to Saxe at al. paper that explains why to use orthogonal init weights\n",
    "    def init(self):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "                    init.constant_(p.data[self.hidden_size:2*self.hidden_size], 1.0)\n",
    "\n",
    "    def consume(self, x):\n",
    "        # encoder forward function\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            h = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h = h.cuda()\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "            pred_usage = self.lin_usage(h)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            h0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            c0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h0 = h0.cuda()\n",
    "                c0 = c0.cuda()\n",
    "            h = (h0, c0)\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "            pred_usage = self.lin_usage(h[0])\n",
    "        return pred_usage, h\n",
    "\n",
    "    def predict(self, pred_usage, h, target_length):\n",
    "        # decoder forward function\n",
    "        preds = []\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                pred_usage = self.lin_usage(h)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                pred_usage = self.lin_usage(h[0])\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        return preds\n",
    "\n",
    "#########################################################################################\n",
    "# Bahdanau Attention model\n",
    "# refer to : AuCson github code\n",
    "# building the model\n",
    "class S2S_BA_Model(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, use_cuda):\n",
    "        super(S2S_BA_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_cuda = use_cuda\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        if self.cell_type not in ['rnn', 'gru', 'lstm']:\n",
    "            raise ValueError(self.cell_type, \" is not an appropriate cell type. Please select one of rnn, gru, or lstm.\")\n",
    "        if self.cell_type == 'rnn':\n",
    "            self.Ecell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.RNNCell(1+self.hidden_size, self.hidden_size)\n",
    "        if self.cell_type == 'gru':\n",
    "            self.Ecell = nn.GRUCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.GRUCell(1+self.hidden_size, self.hidden_size)\n",
    "        if self.cell_type == 'lstm':\n",
    "            self.Ecell = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.LSTMCell(1+self.hidden_size, self.hidden_size)\n",
    "\n",
    "        self.Wattn_energies = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.Wusage = nn.Linear(self.hidden_size, 1)\n",
    "        self.Wout = nn.Linear(1+self.hidden_size*2, self.hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(self.hidden_size))\n",
    "        stdv = 1./math.sqrt(self.v.size(0))\n",
    "        self.v.data.normal_(mean=0, std=stdv)\n",
    "        self.init()\n",
    "\n",
    "# function to intialize weight parameters\n",
    "    def init(self):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "                    init.constant_(p.data[self.hidden_size:2*self.hidden_size], 1.0)\n",
    "\n",
    "    def consume(self, x):\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            # encoder forward function\n",
    "            h = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h = h.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            # encoder part\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h\n",
    "            pred_usage = self.Wusage(h)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            h0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            c0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h0 = h0.cuda()\n",
    "                c0 = c0.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            h = (h0, c0)\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h[0]\n",
    "            pred_usage = self.Wusage(h[0])\n",
    "        return pred_usage, h, encoder_outputs\n",
    "\n",
    "    def predict(self, pred_usage, h, encoder_outputs, target_length):\n",
    "        # decoder with attention function\n",
    "        preds = []\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for step in range(target_length):\n",
    "                h_copies = h.expand(encoder_outputs.shape[0], -1, -1)\n",
    "                energies = torch.tanh(self.Wattn_energies(torch.cat((h_copies, encoder_outputs), 2)))\n",
    "                score = torch.sum(self.v * energies, dim=2)\n",
    "                attn_weights = score.t()\n",
    "                attn_weights = torch.softmax(attn_weights, dim=1).unsqueeze(1)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1)).squeeze(1)\n",
    "                gru_input = torch.cat((pred_usage, context), 1)\n",
    "                h = self.Dcell(gru_input, h)\n",
    "                output = self.Wout(torch.cat((pred_usage, h, context), 1))\n",
    "                pred_usage = self.Wusage(output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for step in range(target_length):\n",
    "                h_copies = h[0].expand(encoder_outputs.shape[0], -1, -1)\n",
    "                energies = torch.tanh(self.Wattn_energies(torch.cat((h_copies, encoder_outputs), 2)))\n",
    "                score = torch.sum(self.v * energies, dim=2)\n",
    "                attn_weights = score.t()\n",
    "                attn_weights = torch.softmax(attn_weights, dim=1).unsqueeze(1)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1)).squeeze(1)\n",
    "                gru_input = torch.cat((pred_usage, context), 1)\n",
    "                h = self.Dcell(gru_input, h)\n",
    "                output = self.Wout(torch.cat((pred_usage, h[0], context), 1))\n",
    "                pred_usage = self.Wusage(output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        return preds\n",
    "\n",
    "#############################################################################################3\n",
    "# Luong Attention module\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        \n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \" is not an appropriate attention method, please select one of dot, general, or concat.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        if self.method == 'concat':\n",
    "            self.attn = nn.Linear(2*self.hidden_size, self.hidden_size)\n",
    "            self.v = nn.Parameter(torch.rand(self.hidden_size))\n",
    "            stdv = 1./math.sqrt(self.v.size(0))\n",
    "            self.v.data.normal_(mean=0, std=stdv)\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        attn_energies = torch.sum(hidden*encoder_output, dim=2)\n",
    "        return attn_energies\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        attn_energies = torch.sum(hidden*energy, dim=2)\n",
    "        return attn_energies\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden.expand(encoder_output.shape[0], -1, -1),\n",
    "                            encoder_output), 2)))\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    # calculate the attention weights (energies) based on the given method\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        if self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        attn_energies = attn_energies.t()\n",
    "        attn_weights = torch.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "        return attn_weights\n",
    "\n",
    "#########################################################################################\n",
    "#  building the S2S LA model\n",
    "class S2S_LA_Model(nn.Module):\n",
    "    def __init__(self, cell_type, attn_method, input_size, hidden_size, use_cuda):\n",
    "        super(S2S_LA_Model, self).__init__()\n",
    "        self.cell_type = cell_type\n",
    "        self.attn_method = attn_method\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.cell_type == 'rnn':\n",
    "            self.Ecell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.RNNCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'gru':\n",
    "            self.Ecell = nn.GRUCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.GRUCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'lstm':\n",
    "            self.Ecell = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.LSTMCell(1, self.hidden_size)\n",
    "\n",
    "        self.lin_usage = nn.Linear(hidden_size, 1)\n",
    "        self.lin_concat = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.attn = Attn(self.attn_method, self.hidden_size)\n",
    "        self.use_cuda = use_cuda\n",
    "        self.init()\n",
    "\n",
    "    # function to intialize weight parameters\n",
    "    def init(self):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "                    init.constant_(p.data[self.hidden_size:2*self.hidden_size], 1.0)\n",
    "\n",
    "    def consume(self, x):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            # encoder forward function\n",
    "            h = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h = h.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            # encoder part\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h\n",
    "            pred_usage = self.lin_usage(h)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            h0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            c0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h0 = h0.cuda()\n",
    "                c0 = c0.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            h = (h0, c0)\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h[0]\n",
    "            pred_usage = self.lin_usage(h[0])\n",
    "        return pred_usage, h, encoder_outputs\n",
    "\n",
    "    def predict(self, pred_usage, h, encoder_outputs, target_length):\n",
    "        # decoder with attention function\n",
    "        preds = []\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                attn_weights = self.attn(h, encoder_outputs)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "                context = context.squeeze(1)\n",
    "                concat_input = torch.cat((h, context), 1)\n",
    "                concat_output = torch.tanh(self.lin_concat(concat_input))\n",
    "                pred_usage = self.lin_usage(concat_output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                attn_weights = self.attn(h[0], encoder_outputs)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "                context = context.squeeze(1)\n",
    "                concat_input = torch.cat((h[0], context), 1)\n",
    "                concat_output = torch.tanh(self.lin_concat(concat_input))\n",
    "                pred_usage = self.lin_usage(concat_output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        return preds\n",
    "\n",
    "#################################################################################################################################################\n",
    "# main function\n",
    "def main(seed, cuda, cell_type, attention_model, la_method, window_source_size,\n",
    "            window_target_size, epochs, batch_size, hs, save_model):\n",
    "    t0 = time.time()\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(\"Loading dataset...\")\n",
    "#     d = np.loadtxt(\"data/Synthetic Site_dataset_2.csv\", delimiter=\",\", skiprows=1, dtype=float)\n",
    "#     # removing unneeded columns\n",
    "#     dataset = d[:, 1:].astype(np.float32)\n",
    "#     dataset = pd.DataFrame(dataset)\n",
    "#     dataset.columns = ['month_of_yr', 'day_of_yr','day_of_month', 'season','day_of_week', 'weekend', 'holiday', 'hour', 'minute', 'temp', 'hum', 'usage']\n",
    "# #     dataset = pd.read_csv(\"data/Synthetic Site_dataset.csv\")\n",
    "# #     dataset = dataset.astype(np.float32)\n",
    "#     # switch around columns\n",
    "# #     dataset = dataset[['month_of_yr', 'day_of_yr','day_of_month', 'season',\n",
    "# #              'day_of_week', 'weekend', 'holiday', 'hour', 'minute', 'temp', 'hum', 'usage']]\n",
    "#     dataset = dataset[['month_of_yr', 'day_of_yr','temp', 'hum', 'usage']]\n",
    "# #     dataset = dataset.drop('minute',1).drop('temp',1).drop('hum',1)\n",
    "\n",
    "    dataset = pd.read_csv(\"data/Synthetic Site_dataset_2.csv\").astype(np.float32)\n",
    "    usage_actual = dataset['usage']\n",
    "    mu_usage = dataset['usage'].mean()\n",
    "    std_usage = dataset['usage'].std()\n",
    "    dataset = dataset.values\n",
    "\n",
    "    # 0 mean and unit var\n",
    "    print(\"Transforming data to 0 mean and unit var\")\n",
    "    MU = dataset.mean(0) # 0 means take the mean of the column\n",
    "    dataset = dataset - MU\n",
    "    STD = dataset.std(0) # same with std here\n",
    "    dataset = dataset / STD\n",
    "\n",
    "    # 5 minutes between rows.\n",
    "    # use 1 hour (12 rows) to predict next half hour (6 rows)\n",
    "    print(\"Generating training and test data...\")\n",
    "    WINDOW_SOURCE_SIZE = window_source_size\n",
    "    WINDOW_TARGET_SIZE = window_target_size\n",
    "\n",
    "    # getting actual usage vector, aligning with predicted values vector. Aka remove first window_source_size and remaining\n",
    "    usage_actual = usage_actual.values\n",
    "    usage_actual = usage_actual[int(dataset.shape[0]*0.80):]\n",
    "    usage_actual = usage_actual[WINDOW_SOURCE_SIZE:]\n",
    "\n",
    "    # 80% train, 20% test\n",
    "    train_source = dataset[:int(dataset.shape[0]*0.80)]\n",
    "    test_source = dataset[int(dataset.shape[0]*0.80):]\n",
    "\n",
    "    # if N = data.shape[0] - (WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE)\n",
    "    # then you will be sliding over every one\n",
    "\n",
    "    def generate_windows(data):\n",
    "        x_train = []\n",
    "        y_usage_train = []\n",
    "        x_test = []\n",
    "        y_usage_test = []\n",
    "\n",
    "        # for training data\n",
    "        idxs = np.random.choice(train_source.shape[0]-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), train_source.shape[0]-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), replace=False)\n",
    "\n",
    "        for idx in idxs:\n",
    "            x_train.append(train_source[idx:idx+WINDOW_SOURCE_SIZE].reshape((1, WINDOW_SOURCE_SIZE, train_source.shape[1])) )\n",
    "            y_usage_train.append(train_source[idx+WINDOW_SOURCE_SIZE:idx+WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE, -1].reshape((1, WINDOW_TARGET_SIZE, 1)) )\n",
    "\n",
    "        x_train = np.concatenate(x_train, axis=0) # make them arrays and not lists\n",
    "        y_usage_train = np.concatenate(y_usage_train, axis=0)\n",
    "\n",
    "        # for testing data\n",
    "        idxs = np.arange(0, len(test_source)-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), WINDOW_TARGET_SIZE)\n",
    "\n",
    "        for idx in idxs:\n",
    "            x_test.append(test_source[idx:idx+WINDOW_SOURCE_SIZE].reshape((1, WINDOW_SOURCE_SIZE, test_source.shape[1])) )\n",
    "            y_usage_test.append(test_source[idx+WINDOW_SOURCE_SIZE:idx+WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE, -1].reshape((1, WINDOW_TARGET_SIZE, 1)) )\n",
    "\n",
    "        x_test = np.concatenate(x_test, axis=0) # make them arrays and not lists\n",
    "        y_usage_test = np.concatenate(y_usage_test, axis=0)\n",
    "\n",
    "        return x_train, y_usage_train, x_test, y_usage_test\n",
    "\n",
    "    X_train, Y_train_usage, X_test, Y_test_usage = generate_windows(dataset)\n",
    "    print(\"Created {} train samples and {} test samples\".format(X_train.shape[0], X_test.shape[0]))\n",
    "    idxs = np.arange(0, len(test_source)-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), WINDOW_TARGET_SIZE)\n",
    "    remainder = len(test_source) - (idxs[-1] + WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE)\n",
    "    usage_actual = usage_actual[:-remainder]\n",
    "\n",
    "#################################################################################################################################################\n",
    "# call the model\n",
    "    #print(\"Creating model...\")\n",
    "    INPUT_SIZE = X_train.shape[-1]\n",
    "    HIDDEN_SIZE = hs\n",
    "    CELL_TYPE = cell_type\n",
    "    LA_METHOD = la_method\n",
    "\n",
    "    # call the respective model\n",
    "    if attention_model == 'none':\n",
    "        model = S2S_Model(CELL_TYPE, INPUT_SIZE, HIDDEN_SIZE, use_cuda=cuda)\n",
    "\n",
    "    elif attention_model == 'BA':\n",
    "        model = S2S_BA_Model(CELL_TYPE, INPUT_SIZE, HIDDEN_SIZE, use_cuda=cuda)\n",
    "\n",
    "    elif attention_model == 'LA':\n",
    "        model = S2S_LA_Model(CELL_TYPE, LA_METHOD, INPUT_SIZE, HIDDEN_SIZE, use_cuda=cuda)\n",
    "\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        model.cuda()\n",
    "\n",
    "    print(\"MODEL ARCHITECTURE IS: \")\n",
    "    print(model)\n",
    "\n",
    "    print(\"\\nModel parameters are on cuda: {}\".format(next(model.parameters()).is_cuda))\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss(reduction='sum')\n",
    "    EPOCHES = epochs\n",
    "    BATCH_SIZE = batch_size\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    for epoch in range(EPOCHES):\n",
    "        t_one_epoch = time.time()\n",
    "        print(\"Epoch {}\".format(epoch+1))\n",
    "        total_usage_loss = 0\n",
    "        for b_idx in range(0, X_train.shape[0], BATCH_SIZE):\n",
    "\n",
    "            x = torch.from_numpy(X_train[b_idx:b_idx+BATCH_SIZE]).float()\n",
    "            y_usage = torch.from_numpy(Y_train_usage[b_idx:b_idx+BATCH_SIZE]).float()\n",
    "\n",
    "            if cuda:\n",
    "                x = x.cuda()\n",
    "                y_usage = y_usage.cuda()\n",
    "\n",
    "            # encoder forward, for respective models (with and without attention)\n",
    "            if attention_model == 'none':\n",
    "                pred_usage, h = model.consume(x)\n",
    "\n",
    "            elif attention_model == 'BA':\n",
    "                pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "            elif attention_model == 'LA':\n",
    "                pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "            # decoder forward, for respective models\n",
    "            if attention_model == 'none':\n",
    "                preds = model.predict(pred_usage, h, WINDOW_TARGET_SIZE)\n",
    "\n",
    "            elif attention_model == 'BA':\n",
    "                preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "            elif attention_model == 'LA':\n",
    "                preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "            # compute lose\n",
    "            loss_usage = loss_fn(preds, y_usage)\n",
    "\n",
    "            # backprop and update\n",
    "            opt.zero_grad()\n",
    "\n",
    "            loss_usage.backward()\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "            total_usage_loss += loss_usage.item()\n",
    "            \n",
    "        train_loss.append(total_usage_loss)\n",
    "        print(\"\\tTRAINING: {} total train USAGE loss.\\n\".format(total_usage_loss))\n",
    "\n",
    "#################################################################################################################################################\n",
    "# TESTING\n",
    "        y_usage = None\n",
    "        pred_usage = None\n",
    "        preds = None\n",
    "        total_usage_loss = 0\n",
    "        all_preds = []\n",
    "\n",
    "        for b_idx in range(0, X_test.shape[0], BATCH_SIZE):\n",
    "            with torch.no_grad():\n",
    "                x = torch.from_numpy(X_test[b_idx:b_idx+BATCH_SIZE])\n",
    "                y_usage = torch.from_numpy(Y_test_usage[b_idx:b_idx+BATCH_SIZE])\n",
    "\n",
    "                if cuda:\n",
    "                    x = x.cuda()\n",
    "                    y_usage = y_usage.cuda()\n",
    "\n",
    "                # encoder forward, for respective models\n",
    "                if attention_model == 'none':\n",
    "                    pred_usage, h = model.consume(x)\n",
    "\n",
    "                elif attention_model == 'BA':\n",
    "                    pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "                elif attention_model == 'LA':\n",
    "                    pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "                # decoder forward, for respective models\n",
    "                if attention_model == 'none':\n",
    "                    preds = model.predict(pred_usage, h, WINDOW_TARGET_SIZE)\n",
    "\n",
    "                elif attention_model == 'BA':\n",
    "                    preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "                elif attention_model == 'LA':\n",
    "                    preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "                # compute loss\n",
    "                loss_usage = loss_fn(preds, y_usage)\n",
    "\n",
    "                total_usage_loss += loss_usage.item()\n",
    "\n",
    "                if (epoch == epochs-1):\n",
    "                    all_preds.append(preds)\n",
    "\n",
    "        test_loss.append(total_usage_loss)\n",
    "\n",
    "        print(\"\\tTESTING: {} total test USAGE loss\".format(total_usage_loss))\n",
    "        print(\"\\tTESTING:\\n\")\n",
    "        print(\"\\tSample of prediction:\")\n",
    "        print(\"\\t\\t TARGET: {}\".format(y_usage[-1].cpu().detach().numpy().flatten()))\n",
    "        print(\"\\t\\t   PRED: {}\\n\\n\".format(preds[-1].cpu().detach().numpy().flatten()))\n",
    "\n",
    "        y_last_usage = y_usage[-1].cpu().detach().numpy().flatten()\n",
    "        pred_last_usage = preds[-1].cpu().detach().numpy().flatten()\n",
    "        t2_one_epoch = time.time()\n",
    "        time_one_epoch = t2_one_epoch - t_one_epoch\n",
    "        print(\"TIME OF ONE EPOCH: {} seconds and {} minutes\".format(time_one_epoch, time_one_epoch/60.0))\n",
    "\n",
    "####################################################################################################\n",
    "# SAVING MODEL\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"MODEL_w:__seed={}_cell_type={}_attention_model={}_la_method={}_T={}_N={}_bs={}_hs={}\".format(\n",
    "            seed, cell_type, attention_model, la_method,\n",
    "            window_source_size, window_target_size, batch_size, hs))\n",
    "\n",
    "#################################################################################################################################################\n",
    "# PLOTTING\n",
    "    # for plotting and accuracy\n",
    "    preds = torch.cat(all_preds, 0)\n",
    "    preds = preds.cpu().detach().numpy().flatten()\n",
    "    actual = Y_test_usage.flatten()\n",
    "\n",
    "    # for loss plotting\n",
    "    train_loss_array = np.asarray(train_loss)\n",
    "    test_loss_array = np.asarray(test_loss)\n",
    "    len_loss = np.arange(len(train_loss_array))\n",
    "\n",
    "    # unnormalizing 1\n",
    "    preds_unnorm = (preds*std_usage) + mu_usage\n",
    "\n",
    "    # using the actual usage from top of script here\n",
    "    mae3 = (sum(abs(usage_actual - preds_unnorm)))/(len(usage_actual))\n",
    "    mape3 = (sum(abs((usage_actual - preds_unnorm)/usage_actual)))/(len(usage_actual))\n",
    "\n",
    "    # for std\n",
    "    mape_s = (abs((usage_actual - preds_unnorm)/usage_actual))\n",
    "    s = mape_s.std()\n",
    "    mae_s = abs(usage_actual - preds_unnorm)\n",
    "    s2 = mae_s.std()\n",
    "    print(\"\\n\\tACTUAL ACC. RESULTS: MAE, MAPE: {} and {}%\".format(mae3, mape3*100.0))\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(1)\n",
    "    plt.plot(np.arange(len(preds)), preds, 'b', label='Predicted')\n",
    "    plt.plot(np.arange(len(actual)), actual, 'g', label='Actual')\n",
    "    plt.title(\"Predicted vs Actual, {} timesteps to {} timesteps\".format(window_source_size, window_target_size))\n",
    "    plt.xlabel(\"Time in 5 minute increments\")\n",
    "    plt.ylabel(\"Usage (normalized)\")\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "#     plt.figure(2)\n",
    "#     plt.plot(np.arange(len(actual)), actual, 'g', label='Actual')\n",
    "#     plt.plot(np.arange(len(preds)), preds, 'b', label='Predicted')\n",
    "#     plt.title(\"Predicted vs Actual, {} timesteps to {} timesteps\".format(window_source_size, window_target_size))\n",
    "#     plt.xlabel(\"Time in 5 minute increments\")\n",
    "#     plt.ylabel(\"Usage (normalized)\")\n",
    "#     plt.legend(loc='lower left')\n",
    "\n",
    "#     plt.figure(3)\n",
    "#     plt.plot(np.arange(len(y_last_usage)), y_last_usage, 'g', label='Actual')\n",
    "#     plt.plot(np.arange(len(pred_last_usage)), pred_last_usage, 'b', label='Predicted')\n",
    "#     plt.title(\"Predicted vs Actual last test example, {} timesteps to {} timesteps\".format(window_source_size, window_target_size))\n",
    "#     plt.xlabel(\"Time in 5 minute increments\")\n",
    "#     plt.ylabel(\"Usage (normalized)\")\n",
    "#     plt.legend(loc='lower left')\n",
    "\n",
    "#     plt.figure(4)\n",
    "#     plt.plot(np.arange(len(usage_actual[-12*24*7:])), usage_actual[-12*24*7:], 'g', label='Actual')\n",
    "#     plt.plot(np.arange(len(preds_unnorm[-12*24*7:])), preds_unnorm[-12*24*7:], 'b', label='Predicted')\n",
    "#     plt.title(\"Predicted vs Actual: Case 2, Zoom last 7 days\".format(window_source_size, window_target_size))\n",
    "#     plt.xlabel(\"Time in 5 minute increments\")\n",
    "#     plt.ylabel(\"Usage (kW)\")\n",
    "#     plt.legend(loc='lower left')\n",
    "\n",
    "#     plt.figure(5)\n",
    "#     plt.plot(len_loss, train_loss_array, 'k')\n",
    "#     plt.title(\"Train loss\")\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "\n",
    "#     plt.figure(6)\n",
    "#     plt.plot(len_loss, test_loss_array, 'r')\n",
    "#     plt.title(\"Test Loss\")\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "\n",
    "    # total time of run\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(\"\\nTIME ELAPSED: {} seconds OR {} minutes\".format(total, total/60.0))\n",
    "    print(\"\\nEnd of run\")\n",
    "    plt.show()\n",
    "    for_plotting = [usage_actual, preds_unnorm, y_last_usage, pred_last_usage]\n",
    "    return s, s2, mape_s, mae_s, mae3, mape3, total/60.0, train_loss, test_loss, for_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    s, s2, mape_s, mae_s, mae, mape, total_mins, train_loss, test_loss, for_plotting = main(seed=0, cuda=True,\n",
    "        cell_type='lstm', attention_model='BA', la_method='none',\n",
    "        window_source_size=12, window_target_size=6, epochs=2,\n",
    "        batch_size=256, hs=64, save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
