{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter as sg_filter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from dateutil import parser\n",
    "from pathlib import Path\n",
    "import json \n",
    "import shutil\n",
    "\n",
    "from wattile.entry_point import create_input_dataframe, run_model\n",
    "from wattile.data_reading import read_dataset_from_file\n",
    "from wattile.time_processing import add_processed_time_columns\n",
    "from wattile.buildings_processing import _preprocess_data, correct_predictor_columns, correct_timestamps, resample_or_rolling_stats, pad_full_data\n",
    "PROJECT_DIRECTORY = Path().resolve().parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For this example, we will be using the default configs.\n",
    "Check out the docs for an explaination of each config.\n",
    "\"\"\"\n",
    "##################################################################################\n",
    "# choose the configs file to use as an input\n",
    "##################################################################################\n",
    "# main configs file\n",
    "with open(PROJECT_DIRECTORY / \"wattile\" / \"configs\" / \"configs.json\", \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "##################################################################################\n",
    "# # code testing configs file\n",
    "# with open(PROJECT_DIRECTORY / \"tests\" / \"fixtures\" / \"test_configs.json\", \"r\") as f:\n",
    "#     configs = json.load(f)\n",
    "##################################################################################\n",
    "\n",
    "configs[\"data_dir\"] = str(PROJECT_DIRECTORY) + \"/data\"\n",
    "configs[\"exp_dir\"] = str(PROJECT_DIRECTORY) + \"/exp_dir\"\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs[\"building\"] = \"Synthetic Site\"\n",
    "# configs[\"target_var\"] = \"Synthetic Site Electricity Main Total Power\"\n",
    "\n",
    "configs[\"building\"] = \"Cafe\"\n",
    "configs[\"target_var\"] = \"Cafe Whole Building Real Power Total\"\n",
    "\n",
    "configs[\"num_epochs\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_dataset_from_file(configs)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = create_input_dataframe(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run (train) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model here or via IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(configs, train_df, val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set configs for applying other data to the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[\"use_case\"] = \"validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read (or set aside) sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read new data here if necessary\n",
    "- example below is using the whole set of data instead of splitting between training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[\"resample_interval\"] = \"15min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.copy()\n",
    "data_sample = data_sample.loc[\"2019-05-01\":\"2019-07-31\"]\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert we have the correct columns and order them\n",
    "data_sample = correct_predictor_columns(configs, data_sample)\n",
    "\n",
    "# sort and trim data specified time period\n",
    "data_sample = correct_timestamps(configs, data_sample)\n",
    "\n",
    "# Add time-based features\n",
    "data_sample = add_processed_time_columns(data_sample, configs)\n",
    "\n",
    "# Add statistics features\n",
    "data_sample = resample_or_rolling_stats(data_sample, configs)\n",
    "\n",
    "# Add lag features\n",
    "configs[\"input_dim\"] = data_sample.shape[1] - 1\n",
    "\n",
    "if configs[\"arch_version\"] == 4:\n",
    "    data_sample = pad_full_data(data_sample, configs)\n",
    "\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### override val_df with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = data_sample.reset_index(drop=True)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(configs, train_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wattile",
   "language": "python",
   "name": "wattile"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
