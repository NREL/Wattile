{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter as sg_filter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from dateutil import parser\n",
    "from pathlib import Path\n",
    "import json \n",
    "import shutil\n",
    "\n",
    "from wattile.data_reading import read_dataset_from_file\n",
    "from wattile.buildings_processing import correct_predictor_columns, correct_timestamps, rolling_stats, input_data_split\n",
    "from wattile.time_processing import add_processed_time_columns\n",
    "PROJECT_DIRECTORY = Path().resolve().parent.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For this example, we will be using the default configs.\n",
    "Check out the docs for an explaination of each config.\n",
    "\"\"\"\n",
    "with open(PROJECT_DIRECTORY / \"wattile\" / \"configs\" / \"configs.json\", \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "\n",
    "exp_dir = PROJECT_DIRECTORY / \"notebooks\" / \"exp_dir\"\n",
    "if exp_dir.exists():\n",
    "    shutil.rmtree(exp_dir)\n",
    "exp_dir.mkdir()\n",
    "\n",
    "configs[\"exp_dir\"] = str(exp_dir)\n",
    "configs[\"data_dir\"] = str(PROJECT_DIRECTORY / \"data\")\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[\"feat_stats\"][\"window_width\"] = '5min'\n",
    "configs[\"feat_stats\"][\"window_increment\"] = '1min'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = configs['building']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_dataset_from_file(configs)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert we have the correct columns and order them\n",
    "data = correct_predictor_columns(configs, data)\n",
    "\n",
    "# sort and trim data specified time period\n",
    "data = correct_timestamps(configs, data)\n",
    "\n",
    "# Add time-based features\n",
    "data = add_processed_time_columns(data, configs)\n",
    "\n",
    "# Add statistics features\n",
    "data = rolling_stats(data, configs)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.reset_index(drop=True)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three types of S2S model structures with different attention model\n",
    "class `S2S_Model`: vanilla S2S model without attention model\n",
    "\n",
    "class `S2S_BA_Model`: S2S model with Bahdanau Attention model (https://machinelearningmastery.com/the-bahdanau-attention-mechanism/)\n",
    "\n",
    "class `S2S_LA_Model`: S2S model with Luong Attention module (https://machinelearningmastery.com/the-luong-attention-mechanism/). `attn` module is part of `S2S_LA_Model`\n",
    "\n",
    "Each model structure can select RNN cell type, including `lstm`, `RNN`, `gru`\n",
    "\n",
    "Three model structures are parallel. Each run defines one model structure. The selection of model structure is only used for sensitivity analysis and comparison study. In the future when we decide one model structure, we can delete the rest options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "# building the S2S model\n",
    "class S2S_Model(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, use_cuda):\n",
    "        super(S2S_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        if self.cell_type not in ['rnn', 'gru', 'lstm']:\n",
    "            raise ValueError(self.cell_type, \" is not an appropriate cell type. Please select one of rnn, gru, or lstm.\")\n",
    "        if self.cell_type == 'rnn':\n",
    "            self.Ecell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.RNNCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'gru':\n",
    "            self.Ecell = nn.GRUCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.GRUCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'lstm':\n",
    "            self.Ecell = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.LSTMCell(1, self.hidden_size)\n",
    "\n",
    "        self.lin_usage = nn.Linear(self.hidden_size, 1)\n",
    "        self.use_cuda = use_cuda\n",
    "        self.init()\n",
    "\n",
    "    # function to intialize weight parameters. Refer to Saxe at al. paper that explains why to use orthogonal init weights\n",
    "    def init(self):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "                    init.constant_(p.data[self.hidden_size:2*self.hidden_size], 1.0)\n",
    "\n",
    "    def consume(self, x):\n",
    "        # encoder forward function\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            h = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h = h.cuda()\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "            pred_usage = self.lin_usage(h)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            h0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            c0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h0 = h0.cuda()\n",
    "                c0 = c0.cuda()\n",
    "            h = (h0, c0)\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "            pred_usage = self.lin_usage(h[0])\n",
    "        return pred_usage, h\n",
    "\n",
    "    def predict(self, pred_usage, h, target_length):\n",
    "        # decoder forward function\n",
    "        preds = []\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                pred_usage = self.lin_usage(h)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                pred_usage = self.lin_usage(h[0])\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        return preds\n",
    "\n",
    "#########################################################################################\n",
    "# Bahdanau Attention model\n",
    "# refer to : AuCson github code\n",
    "# building the model\n",
    "class S2S_BA_Model(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, use_cuda):\n",
    "        super(S2S_BA_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_cuda = use_cuda\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        if self.cell_type not in ['rnn', 'gru', 'lstm']:\n",
    "            raise ValueError(self.cell_type, \" is not an appropriate cell type. Please select one of rnn, gru, or lstm.\")\n",
    "        if self.cell_type == 'rnn':\n",
    "            self.Ecell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.RNNCell(1+self.hidden_size, self.hidden_size)\n",
    "        if self.cell_type == 'gru':\n",
    "            self.Ecell = nn.GRUCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.GRUCell(1+self.hidden_size, self.hidden_size)\n",
    "        if self.cell_type == 'lstm':\n",
    "            self.Ecell = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.LSTMCell(1+self.hidden_size, self.hidden_size)\n",
    "\n",
    "        self.Wattn_energies = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.Wusage = nn.Linear(self.hidden_size, 1)\n",
    "        self.Wout = nn.Linear(1+self.hidden_size*2, self.hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(self.hidden_size))\n",
    "        stdv = 1./math.sqrt(self.v.size(0))\n",
    "        self.v.data.normal_(mean=0, std=stdv)\n",
    "        self.init()\n",
    "\n",
    "# function to intialize weight parameters\n",
    "    def init(self):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "                    init.constant_(p.data[self.hidden_size:2*self.hidden_size], 1.0)\n",
    "\n",
    "    def consume(self, x):\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            # encoder forward function\n",
    "            h = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h = h.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            # encoder part\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h\n",
    "            pred_usage = self.Wusage(h)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            h0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            c0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h0 = h0.cuda()\n",
    "                c0 = c0.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            h = (h0, c0)\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h[0]\n",
    "            pred_usage = self.Wusage(h[0])\n",
    "        return pred_usage, h, encoder_outputs\n",
    "\n",
    "    def predict(self, pred_usage, h, encoder_outputs, target_length):\n",
    "        # decoder with attention function\n",
    "        preds = []\n",
    "        # for rnn and gru\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for step in range(target_length):\n",
    "                h_copies = h.expand(encoder_outputs.shape[0], -1, -1)\n",
    "                energies = torch.tanh(self.Wattn_energies(torch.cat((h_copies, encoder_outputs), 2)))\n",
    "                score = torch.sum(self.v * energies, dim=2)\n",
    "                attn_weights = score.t()\n",
    "                attn_weights = torch.softmax(attn_weights, dim=1).unsqueeze(1)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1)).squeeze(1)\n",
    "                gru_input = torch.cat((pred_usage, context), 1)\n",
    "                h = self.Dcell(gru_input, h)\n",
    "                output = self.Wout(torch.cat((pred_usage, h, context), 1))\n",
    "                pred_usage = self.Wusage(output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        # for lstm\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for step in range(target_length):\n",
    "                h_copies = h[0].expand(encoder_outputs.shape[0], -1, -1)\n",
    "                energies = torch.tanh(self.Wattn_energies(torch.cat((h_copies, encoder_outputs), 2)))\n",
    "                score = torch.sum(self.v * energies, dim=2)\n",
    "                attn_weights = score.t()\n",
    "                attn_weights = torch.softmax(attn_weights, dim=1).unsqueeze(1)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1)).squeeze(1)\n",
    "                gru_input = torch.cat((pred_usage, context), 1)\n",
    "                h = self.Dcell(gru_input, h)\n",
    "                output = self.Wout(torch.cat((pred_usage, h[0], context), 1))\n",
    "                pred_usage = self.Wusage(output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        return preds\n",
    "\n",
    "#############################################################################################3\n",
    "# Luong Attention module\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        \n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \" is not an appropriate attention method, please select one of dot, general, or concat.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        if self.method == 'concat':\n",
    "            self.attn = nn.Linear(2*self.hidden_size, self.hidden_size)\n",
    "            self.v = nn.Parameter(torch.rand(self.hidden_size))\n",
    "            stdv = 1./math.sqrt(self.v.size(0))\n",
    "            self.v.data.normal_(mean=0, std=stdv)\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        attn_energies = torch.sum(hidden*encoder_output, dim=2)\n",
    "        return attn_energies\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        attn_energies = torch.sum(hidden*energy, dim=2)\n",
    "        return attn_energies\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden.expand(encoder_output.shape[0], -1, -1),\n",
    "                            encoder_output), 2)))\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    # calculate the attention weights (energies) based on the given method\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        if self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        attn_energies = attn_energies.t()\n",
    "        attn_weights = torch.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "        return attn_weights\n",
    "\n",
    "#########################################################################################\n",
    "#  building the S2S LA model\n",
    "class S2S_LA_Model(nn.Module):\n",
    "    def __init__(self, cell_type, attn_method, input_size, hidden_size, use_cuda):\n",
    "        super(S2S_LA_Model, self).__init__()\n",
    "        self.cell_type = cell_type\n",
    "        self.attn_method = attn_method\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.cell_type == 'rnn':\n",
    "            self.Ecell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.RNNCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'gru':\n",
    "            self.Ecell = nn.GRUCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.GRUCell(1, self.hidden_size)\n",
    "        if self.cell_type == 'lstm':\n",
    "            self.Ecell = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "            self.Dcell = nn.LSTMCell(1, self.hidden_size)\n",
    "\n",
    "        self.lin_usage = nn.Linear(hidden_size, 1)\n",
    "        self.lin_concat = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.attn = Attn(self.attn_method, self.hidden_size)\n",
    "        self.use_cuda = use_cuda\n",
    "        self.init()\n",
    "\n",
    "    # function to intialize weight parameters\n",
    "    def init(self):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for p in self.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    init.orthogonal_(p.data, gain=1.0)\n",
    "                if p.dim() == 1:\n",
    "                    init.constant_(p.data, 0.0)\n",
    "                    init.constant_(p.data[self.hidden_size:2*self.hidden_size], 1.0)\n",
    "\n",
    "    def consume(self, x):\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            # encoder forward function\n",
    "            h = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h = h.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            # encoder part\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h\n",
    "            pred_usage = self.lin_usage(h)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            h0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            c0 = torch.zeros(x.shape[0], self.hidden_size)\n",
    "            encoder_outputs = torch.zeros(x.shape[1], x.shape[0], self.hidden_size)\n",
    "            if self.use_cuda:\n",
    "                h0 = h0.cuda()\n",
    "                c0 = c0.cuda()\n",
    "                encoder_outputs = encoder_outputs.cuda()\n",
    "            h = (h0, c0)\n",
    "            for T in range(x.shape[1]):\n",
    "                h = self.Ecell(x[:, T, :], h)\n",
    "                encoder_outputs[T] = h[0]\n",
    "            pred_usage = self.lin_usage(h[0])\n",
    "        return pred_usage, h, encoder_outputs\n",
    "\n",
    "    def predict(self, pred_usage, h, encoder_outputs, target_length):\n",
    "        # decoder with attention function\n",
    "        preds = []\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                attn_weights = self.attn(h, encoder_outputs)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "                context = context.squeeze(1)\n",
    "                concat_input = torch.cat((h, context), 1)\n",
    "                concat_output = torch.tanh(self.lin_concat(concat_input))\n",
    "                pred_usage = self.lin_usage(concat_output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        elif self.cell_type == 'lstm':\n",
    "            for step in range(target_length):\n",
    "                h = self.Dcell(pred_usage, h)\n",
    "                attn_weights = self.attn(h[0], encoder_outputs)\n",
    "                context = attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "                context = context.squeeze(1)\n",
    "                concat_input = torch.cat((h[0], context), 1)\n",
    "                concat_output = torch.tanh(self.lin_concat(concat_input))\n",
    "                pred_usage = self.lin_usage(concat_output)\n",
    "                preds.append(pred_usage.unsqueeze(1))\n",
    "            preds = torch.cat(preds, 1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main function\n",
    "\n",
    "The `main` function process the data into three-dimensional for S2S model, train the model, and test the restuls\n",
    "\n",
    "- def `generate_windows`: an important procedure to convert 2-dimensional data into 3-dimensional for modeling\n",
    "\n",
    "- def `quantile_loss`: loss function with quntile number as parameter. For now, it cannot support list of quantiles as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################################################\n",
    "# main function\n",
    "def main(seed, cuda, cell_type, attention_model, la_method, window_source_size,\n",
    "            window_target_size, epochs, batch_size, hs, save_model, loss_function_qs, normalization):\n",
    "    t0 = time.time()\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # loss function, qs here is an integer, not a list of integer\n",
    "    def quantile_loss(output, target, qs, window_target_size):\n",
    "        \"\"\"\n",
    "        Computes loss for quantile methods.\n",
    "        :param output: (Tensor)\n",
    "        :param target: (Tensor)\n",
    "        :param qs: (int)\n",
    "        :param window_target_size: (int)\n",
    "        :return: (Tensor) Loss for this study (single number)\n",
    "        \"\"\"\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        resid = target - output\n",
    "        tau = torch.tensor([qs], device=device).repeat_interleave(window_target_size)\n",
    "\n",
    "        alpha = 0.001\n",
    "        log_term = torch.zeros_like(resid, device=device)\n",
    "        log_term[resid < 0] = torch.log(1 + torch.exp(resid[resid < 0] / alpha)) - (\n",
    "            resid[resid < 0] / alpha\n",
    "        )\n",
    "        log_term[resid >= 0] = torch.log(1 + torch.exp(-resid[resid >= 0] / alpha))\n",
    "        loss = resid * tau + alpha * log_term\n",
    "        loss = torch.mean(torch.mean(loss, 0))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    #################################################################\n",
    "    # Load dataset\n",
    "    #################################################################\n",
    "    # if site == 'cafe':\n",
    "    #     dataset = pd.read_csv(\"data/Cafe_dataset_2.csv\").astype(np.float32)\n",
    "    # elif site == 'synthetic':\n",
    "    #     dataset = pd.read_csv(\"data/Synthetic Site_dataset_2.csv\").astype(np.float32)        \n",
    "    # else: \n",
    "    #     raise Exception(\"The variable of 'site' should either be 'cafe' or 'synthetic'.\")\n",
    "    #################################################################\n",
    "    dataset = data.astype(np.float32).copy() ###################################################################\n",
    "    #################################################################\n",
    "        \n",
    "    #################################################################\n",
    "    usage_actual = dataset[configs['target_var']]\n",
    "    mu_usage = dataset[configs['target_var']].mean()\n",
    "    std_usage = dataset[configs['target_var']].std()\n",
    "    dataset = dataset.values\n",
    "    #################################################################\n",
    "\n",
    "    # Normalization\n",
    "    if normalization: \n",
    "        print(f\"Transforming data to 0 mean and unit var\")\n",
    "        MU = dataset.mean(0) # 0 means take the mean of the column\n",
    "        dataset = dataset - MU\n",
    "        STD = dataset.std(0) # same with std here\n",
    "        dataset = dataset / STD\n",
    "    else:\n",
    "        MU = dataset.mean(0) # 0 means take the mean of the column\n",
    "        MU = 0\n",
    "        dataset = dataset - MU\n",
    "        STD = dataset.std(0) # same with std here\n",
    "        STD = 1\n",
    "        dataset = dataset / STD\n",
    "\n",
    "    print(\"Generating training and test data...\")\n",
    "    WINDOW_SOURCE_SIZE = window_source_size\n",
    "    WINDOW_TARGET_SIZE = window_target_size\n",
    "\n",
    "    #################################################################\n",
    "    # getting actual usage vector, aligning with predicted values vector. Aka remove first window_source_size and remaining\n",
    "    #################################################################\n",
    "    usage_actual = usage_actual.values\n",
    "    usage_actual = usage_actual[int(dataset.shape[0]*0.80):]\n",
    "    usage_actual = usage_actual[WINDOW_SOURCE_SIZE:]\n",
    "    \n",
    "    #################################################################\n",
    "    # training testing split: 80% train, 20% test\n",
    "    #################################################################\n",
    "    train_source = dataset[:int(dataset.shape[0]*0.80)]\n",
    "    test_source = dataset[int(dataset.shape[0]*0.80):]\n",
    "    #################################################################\n",
    "#     train_source, test_source = input_data_split(data, configs)\n",
    "#     usage_actual = train_source[[configs['target_var']]].values\n",
    "#     usage_actual = usage_actual[WINDOW_SOURCE_SIZE:]\n",
    "#     train_source = train_source.values\n",
    "#     test_source = test_source.values\n",
    "    #################################################################\n",
    "\n",
    "\n",
    "    # A key function to convert from 2D data to 3D data. \n",
    "    def generate_windows(data):\n",
    "        x_train = []\n",
    "        y_usage_train = []\n",
    "        x_test = []\n",
    "        y_usage_test = []\n",
    "\n",
    "        # for training data\n",
    "        idxs = np.random.choice(train_source.shape[0]-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), train_source.shape[0]-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), replace=False)\n",
    "\n",
    "        for idx in idxs:\n",
    "            x_train.append(train_source[idx:idx+WINDOW_SOURCE_SIZE].reshape((1, WINDOW_SOURCE_SIZE, train_source.shape[1])) )\n",
    "            y_usage_train.append(train_source[idx+WINDOW_SOURCE_SIZE:idx+WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE, -1].reshape((1, WINDOW_TARGET_SIZE, 1)) )\n",
    "\n",
    "        x_train = np.concatenate(x_train, axis=0) # make them arrays and not lists\n",
    "        y_usage_train = np.concatenate(y_usage_train, axis=0)\n",
    "\n",
    "        # for testing data\n",
    "        idxs = np.arange(0, len(test_source)-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), WINDOW_TARGET_SIZE)\n",
    "\n",
    "        for idx in idxs:\n",
    "            x_test.append(test_source[idx:idx+WINDOW_SOURCE_SIZE].reshape((1, WINDOW_SOURCE_SIZE, test_source.shape[1])) )\n",
    "            y_usage_test.append(test_source[idx+WINDOW_SOURCE_SIZE:idx+WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE, -1].reshape((1, WINDOW_TARGET_SIZE, 1)) )\n",
    "\n",
    "        x_test = np.concatenate(x_test, axis=0) # make them arrays and not lists\n",
    "        y_usage_test = np.concatenate(y_usage_test, axis=0)\n",
    "\n",
    "        return x_train, y_usage_train, x_test, y_usage_test\n",
    "\n",
    "    X_train, Y_train_usage, X_test, Y_test_usage = generate_windows(dataset)\n",
    "    print(\"Created {} train samples and {} test samples\".format(X_train.shape[0], X_test.shape[0]))\n",
    "    idxs = np.arange(0, len(test_source)-(WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE), WINDOW_TARGET_SIZE)\n",
    "    remainder = len(test_source) - (idxs[-1] + WINDOW_SOURCE_SIZE+WINDOW_TARGET_SIZE)\n",
    "    usage_actual = usage_actual[:-remainder]\n",
    "\n",
    "#################################################################################################################################################\n",
    "# call the model\n",
    "    #print(\"Creating model...\")\n",
    "    INPUT_SIZE = X_train.shape[-1]\n",
    "    HIDDEN_SIZE = hs\n",
    "    CELL_TYPE = cell_type\n",
    "    LA_METHOD = la_method\n",
    "\n",
    "    # call the respective model\n",
    "    if attention_model == 'none':\n",
    "        model = S2S_Model(CELL_TYPE, INPUT_SIZE, HIDDEN_SIZE, use_cuda=cuda)\n",
    "\n",
    "    elif attention_model == 'BA':\n",
    "        model = S2S_BA_Model(CELL_TYPE, INPUT_SIZE, HIDDEN_SIZE, use_cuda=cuda)\n",
    "\n",
    "    elif attention_model == 'LA':\n",
    "        model = S2S_LA_Model(CELL_TYPE, LA_METHOD, INPUT_SIZE, HIDDEN_SIZE, use_cuda=cuda)\n",
    "\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        model.cuda()\n",
    "\n",
    "    print(\"MODEL ARCHITECTURE IS: \")\n",
    "    print(model)\n",
    "\n",
    "    print(\"\\nModel parameters are on cuda: {}\".format(next(model.parameters()).is_cuda))\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#     loss_fn = nn.MSELoss(reduction='sum')\n",
    "    loss_fn = quantile_loss\n",
    "    \n",
    "    EPOCHES = epochs\n",
    "    BATCH_SIZE = batch_size\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    for epoch in range(EPOCHES):\n",
    "        t_one_epoch = time.time()\n",
    "        print(\"Epoch {}\".format(epoch+1))\n",
    "        total_usage_loss = 0\n",
    "        for b_idx in range(0, X_train.shape[0], BATCH_SIZE):\n",
    "\n",
    "            x = torch.from_numpy(X_train[b_idx:b_idx+BATCH_SIZE]).float()\n",
    "            y_usage = torch.from_numpy(Y_train_usage[b_idx:b_idx+BATCH_SIZE]).float()\n",
    "\n",
    "            if cuda:\n",
    "                x = x.cuda()\n",
    "                y_usage = y_usage.cuda()\n",
    "\n",
    "            # encoder forward, for respective models (with and without attention)\n",
    "            if attention_model == 'none':\n",
    "                pred_usage, h = model.consume(x)\n",
    "\n",
    "            elif attention_model == 'BA':\n",
    "                pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "            elif attention_model == 'LA':\n",
    "                pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "            # decoder forward, for respective models\n",
    "            if attention_model == 'none':\n",
    "                preds = model.predict(pred_usage, h, WINDOW_TARGET_SIZE)\n",
    "\n",
    "            elif attention_model == 'BA':\n",
    "                preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "            elif attention_model == 'LA':\n",
    "                preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "            # compute lose\n",
    "            loss_usage = loss_fn(preds, y_usage, qs = loss_function_qs, window_target_size=window_target_size)\n",
    "\n",
    "            # backprop and update\n",
    "            opt.zero_grad()\n",
    "\n",
    "            loss_usage.sum().backward()\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "#             total_usage_loss += loss_usage.item()\n",
    "            \n",
    "        train_loss.append(total_usage_loss)\n",
    "        print(\"\\tTRAINING: {} total train USAGE loss.\\n\".format(total_usage_loss))\n",
    "\n",
    "#################################################################################################################################################\n",
    "# TESTING\n",
    "        y_usage = None\n",
    "        pred_usage = None\n",
    "        preds = None\n",
    "        total_usage_loss = 0\n",
    "        all_preds = []\n",
    "\n",
    "        for b_idx in range(0, X_test.shape[0], BATCH_SIZE):\n",
    "            with torch.no_grad():\n",
    "                x = torch.from_numpy(X_test[b_idx:b_idx+BATCH_SIZE])\n",
    "                y_usage = torch.from_numpy(Y_test_usage[b_idx:b_idx+BATCH_SIZE])\n",
    "\n",
    "                if cuda:\n",
    "                    x = x.cuda()\n",
    "                    y_usage = y_usage.cuda()\n",
    "\n",
    "                # encoder forward, for respective models\n",
    "                if attention_model == 'none':\n",
    "                    pred_usage, h = model.consume(x)\n",
    "\n",
    "                elif attention_model == 'BA':\n",
    "                    pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "                elif attention_model == 'LA':\n",
    "                    pred_usage, h, encoder_outputs = model.consume(x)\n",
    "\n",
    "                # decoder forward, for respective models\n",
    "                if attention_model == 'none':\n",
    "                    preds = model.predict(pred_usage, h, WINDOW_TARGET_SIZE)\n",
    "\n",
    "                elif attention_model == 'BA':\n",
    "                    preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "                elif attention_model == 'LA':\n",
    "                    preds = model.predict(pred_usage, h, encoder_outputs, WINDOW_TARGET_SIZE)\n",
    "\n",
    "                # compute loss\n",
    "                loss_usage = loss_fn(preds, y_usage, qs = loss_function_qs, window_target_size=window_target_size)\n",
    "\n",
    "                if (epoch == epochs-1):\n",
    "                    all_preds.append(preds)\n",
    "\n",
    "        test_loss.append(total_usage_loss)\n",
    "\n",
    "        print(\"\\tTESTING: {} total test USAGE loss\".format(total_usage_loss))\n",
    "        print(\"\\tTESTING:\\n\")\n",
    "        print(\"\\tSample of prediction:\")\n",
    "        print(\"\\t\\t TARGET: {}\".format(y_usage[-1].cpu().detach().numpy().flatten()))\n",
    "        print(\"\\t\\t   PRED: {}\\n\\n\".format(preds[-1].cpu().detach().numpy().flatten()))\n",
    "\n",
    "        y_last_usage = y_usage[-1].cpu().detach().numpy().flatten()\n",
    "        pred_last_usage = preds[-1].cpu().detach().numpy().flatten()\n",
    "        t2_one_epoch = time.time()\n",
    "        time_one_epoch = t2_one_epoch - t_one_epoch\n",
    "        print(\"TIME OF ONE EPOCH: {} seconds and {} minutes\".format(time_one_epoch, time_one_epoch/60.0))\n",
    "\n",
    "####################################################################################################\n",
    "# SAVING MODEL\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"MODEL_w:__seed={}_cell_type={}_attention_model={}_la_method={}_T={}_N={}_bs={}_hs={}\".format(\n",
    "            seed, cell_type, attention_model, la_method,\n",
    "            window_source_size, window_target_size, batch_size, hs))\n",
    "\n",
    "#################################################################################################################################################\n",
    "# RESULTS\n",
    "    # for plotting and accuracy\n",
    "    preds = torch.cat(all_preds, 0)\n",
    "    preds = preds.cpu().detach().numpy().flatten()\n",
    "    actual = Y_test_usage.flatten()\n",
    "\n",
    "    # for loss plotting\n",
    "    train_loss_array = np.asarray(train_loss)\n",
    "    test_loss_array = np.asarray(test_loss)\n",
    "    len_loss = np.arange(len(train_loss_array))\n",
    "\n",
    "    # unnormalizing 1\n",
    "    if normalization:\n",
    "        preds_unnorm = (preds*std_usage) + mu_usage\n",
    "    else:\n",
    "        preds_unnorm = preds\n",
    "\n",
    "    # using the actual usage from top of script here\n",
    "    mae3 = (sum(abs(usage_actual - preds_unnorm)))/(len(usage_actual))\n",
    "    mape3 = (sum(abs((usage_actual - preds_unnorm)/usage_actual)))/(len(usage_actual))\n",
    "\n",
    "    # for std\n",
    "    mape_s = (abs((usage_actual - preds_unnorm)/usage_actual))\n",
    "    s = mape_s.std()\n",
    "    mae_s = abs(usage_actual - preds_unnorm)\n",
    "    s2 = mae_s.std()\n",
    "    print(\"\\n\\tACTUAL ACC. RESULTS: MAE, MAPE: {} and {}%\".format(mae3, mape3*100.0))\n",
    "    \n",
    "    if not os.path.exists(f'results/{site}'):\n",
    "        os.makedirs(f'results/{site}')\n",
    "    \n",
    "    pd.DataFrame(preds, columns = [f'q{loss_function_qs}']).to_csv(f'results/{site}/q{loss_function_qs}.csv', index = None)\n",
    "    pd.DataFrame(actual, columns = [f'actual']).to_csv(f'results/{site}/actual.csv', index = None)\n",
    "\n",
    "    # total time of run\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(\"\\nTIME ELAPSED: {} seconds OR {} minutes\".format(total, total/60.0))\n",
    "    print(\"\\nEnd of run\")\n",
    "    plt.show()\n",
    "    for_plotting = [usage_actual, preds_unnorm, y_last_usage, pred_last_usage]\n",
    "    return s, s2, mape_s, mae_s, mae3, mape3, total/60.0, train_loss, test_loss, for_plotting, MU, STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cafe data is too large to set a high epochs number to run on my local machine\n",
    "# if site == 'cafe':\n",
    "#     n_epochs = 1\n",
    "# elif site == 'synthetic':\n",
    "#     n_epochs = 10\n",
    "# else:\n",
    "#     raise Exception(\"The variable of 'site' should either be 'cafe' or 'synthetic'.\")\n",
    "n_epochs = 100\n",
    "\n",
    "for loss_function_qs in [0.05, 0.25, 0.50, 0.75, 0.95]: #[0.50]:#[0.05, 0.50, 0.95]:\n",
    "    print(f\"Processing loss function alpha: {loss_function_qs}\")\n",
    "    if __name__ == \"__main__\":\n",
    "        s, s2, mape_s, mae_s, mae, mape, total_mins, train_loss, test_loss, for_plotting, MU, STD = main(\n",
    "            seed=42, \n",
    "            cuda=False,\n",
    "            cell_type='lstm', \n",
    "            attention_model='BA', \n",
    "            la_method='none',\n",
    "            window_source_size=12, ########################################\n",
    "            window_target_size=3,  ########################################\n",
    "            epochs=n_epochs,\n",
    "            batch_size=256, \n",
    "            hs=64, \n",
    "            save_model=False, \n",
    "            loss_function_qs = loss_function_qs, \n",
    "            normalization = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q95 = pd.read_csv(f'results/{site}/q0.95.csv')\n",
    "q75 = pd.read_csv(f'results/{site}/q0.75.csv')\n",
    "q50 = pd.read_csv(f'results/{site}/q0.5.csv')\n",
    "q25 = pd.read_csv(f'results/{site}/q0.25.csv')\n",
    "q05 = pd.read_csv(f'results/{site}/q0.05.csv')\n",
    "actual = pd.read_csv(f'results/{site}/actual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4.5))\n",
    "\n",
    "plt.title(f'{site} Whole Building Real Power Total Prediction')\n",
    "\n",
    "plt.plot(actual, label = 'actual')\n",
    "plt.plot(sg_filter(q95.values.flatten(),5,2), label = 'Q95', color = '#a2a2a2')\n",
    "plt.plot(sg_filter(q75.values.flatten(),5,2), label = 'Q75', color = '#5b5b5b')\n",
    "plt.plot(sg_filter(q50.values.flatten(),5,2), label = 'Medium', color = '#322b2b')\n",
    "plt.plot(sg_filter(q25.values.flatten(),5,2), label = 'Q25', color = '#5b5b5b')\n",
    "plt.plot(sg_filter(q05.values.flatten(),5,2), label = 'Q5', color = '#a2a2a2')\n",
    "\n",
    "plt.legend()\n",
    "#plt.ylim(80,140)\n",
    "n = 0\n",
    "#plt.xlim(240 + n, 480 + n)\n",
    "\n",
    "plt.ylabel(f'{site} Whole Building Real Power Total')\n",
    "plt.xlabel('Timesteps, 1 min/unit, showing 4 hours results')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4.5))\n",
    "\n",
    "plt.title(f'{site} Whole Building Real Power Total Prediction')\n",
    "\n",
    "plt.plot(actual, label = 'actual')\n",
    "plt.plot(sg_filter(q95.values.flatten(),5,2), label = 'Q95', color = '#a2a2a2')\n",
    "plt.plot(sg_filter(q75.values.flatten(),5,2), label = 'Q75', color = '#5b5b5b')\n",
    "plt.plot(sg_filter(q50.values.flatten(),5,2), label = 'Medium', color = '#322b2b')\n",
    "plt.plot(sg_filter(q25.values.flatten(),5,2), label = 'Q25', color = '#5b5b5b')\n",
    "plt.plot(sg_filter(q05.values.flatten(),5,2), label = 'Q5', color = '#a2a2a2')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#plt.ylim(40,150)\n",
    "n=0\n",
    "#plt.xlim(1000, 1720)\n",
    "\n",
    "plt.ylabel(f'{site} Whole Building Real Power Total')\n",
    "plt.xlabel('Timesteps, 1 min/unit, showing 12 hours results')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4.5))\n",
    "\n",
    "# calculating error\n",
    "y_actual = actual\n",
    "y_predicted = q50.values.flatten()\n",
    "MSE = mean_squared_error(y_actual, y_predicted)\n",
    "RMSE = MSE**0.5\n",
    "CV_RMSE = RMSE/y_actual.mean().values[0]\n",
    "mae = mean_absolute_error(y_actual, y_predicted)\n",
    "\n",
    "plt.title(f'{site} Whole Building Real Power Total Prediction\\nError: MAE:{mae:.2f} kW, CV-RMSE:{CV_RMSE*100:.2f}%')\n",
    "\n",
    "plt.plot(actual, label = 'actual')\n",
    "plt.plot(sg_filter(q95.values.flatten(),5,2), label = 'Q95', color = '#a2a2a2')\n",
    "plt.plot(sg_filter(q75.values.flatten(),5,2), label = 'Q75', color = '#5b5b5b')\n",
    "plt.plot(sg_filter(q50.values.flatten(),5,2), label = 'Medium', color = '#322b2b')\n",
    "plt.plot(sg_filter(q25.values.flatten(),5,2), label = 'Q25', color = '#5b5b5b')\n",
    "plt.plot(sg_filter(q05.values.flatten(),5,2), label = 'Q5', color = '#a2a2a2')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# plt.ylim(20,40)\n",
    "# n=0\n",
    "# plt.xlim(1000, 1720)\n",
    "\n",
    "plt.ylabel(f'{site} Whole Building Real Power Total')\n",
    "plt.xlabel('Timesteps, 1 min/unit, showing 33 hours results')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watt",
   "language": "python",
   "name": "watt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
