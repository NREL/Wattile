{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from wattile.entry_point import init_logging, create_input_dataframe, run_model\n",
    "from wattile.data_reading import read_dataset_from_file\n",
    "from wattile.buildings_processing import prep_for_rnn, rolling_stats, pad_full_data, input_data_split\n",
    "from wattile.entry_point import run_model\n",
    "\n",
    "PROJECT_DIRECTORY = Path().resolve().parent.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "For this example, we will be using the default configs.\n",
    "Check out the docs for an explaination of each config.\n",
    "\"\"\"\n",
    "with open(PROJECT_DIRECTORY / \"wattile\" / \"configs\" / \"configs.json\", \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "\n",
    "exp_dir = PROJECT_DIRECTORY / \"notebooks\" / \"exp_dir\"\n",
    "if exp_dir.exists():\n",
    "    shutil.rmtree(exp_dir)\n",
    "exp_dir.mkdir()\n",
    "\n",
    "configs[\"exp_dir\"] = str(exp_dir)\n",
    "configs[\"data_dir\"] = str(PROJECT_DIRECTORY / \"data\")\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"incomplete small example data2\" # complete example data, incomplete example data, incomplete small example data\n",
    "incompleteness = True\n",
    "# col_test = ['Synthetic Weather Station Direct Normal Irradiance']\n",
    "col_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datatype == \"complete example data\":\n",
    "    \"\"\"\n",
    "    Firstly, we will read the raw data from the dataset. \n",
    "    Checkout the docs for an indepth explaination of necessary dataset structure.\n",
    "    \"\"\"\n",
    "    data = read_dataset_from_file(configs)\n",
    "    data\n",
    "    \n",
    "    if incompleteness == True:\n",
    "        \n",
    "        # data_temp = data.loc[\"2021-12-01\":\"2021-12-01\" :,].copy()\n",
    "        data_temp = data.copy()\n",
    "        data_temp\n",
    "\n",
    "        # adding irregular measurement intervals\n",
    "        list_cols = ['Synthetic Weather Station Dew Point Temperature', 'Synthetic Weather Station Diffuse Horizontal Irradiance', 'Synthetic Weather Station Global Horizontal Irradiance']\n",
    "        list_interval_mins = [3, 5, 7]\n",
    "        list_timeshift_mins = [0, 3, 7]\n",
    "        \n",
    "        i=0\n",
    "    \n",
    "        for col, timestep, loffset in zip(list_cols, list_interval_mins, list_timeshift_mins):\n",
    "\n",
    "            print(\"resampling and shifting column = {} with resampling timestep of {} and time-shift of {}\".format(col, timestep, loffset))\n",
    "\n",
    "            minutes = str(timestep) + \"T\"\n",
    "            loffset = str(loffset) + \"min\" \n",
    "            df_temp = data_temp[col].resample(minutes).mean().copy()\n",
    "            df_temp.index = df_temp.index + to_offset(loffset)\n",
    "            data_temp[col] = df_temp\n",
    "\n",
    "        # adding NaNs in random places\n",
    "        fraction = 0.1\n",
    "        list_index_random = data_temp.sample(frac=fraction, replace=False, random_state=1).index.tolist()\n",
    "        list_column_random = pd.DataFrame(data_temp.columns).sample(frac=fraction, replace=False, random_state=2).iloc[:,0].tolist()\n",
    "\n",
    "        i=0\n",
    "        for ind in list_index_random:\n",
    "\n",
    "            for col in list_column_random:\n",
    "\n",
    "                #print(\"replacing value in index = {} and column = {} to blank\".format(ind, col))\n",
    "                data_temp.loc[ data_temp.index==ind , data_temp.columns==col ] = np.NAN\n",
    "                \n",
    "        # adding irregular/random timestamps\n",
    "        def random_dates(start, end, n):\n",
    "\n",
    "            start_u = start.value//10**9\n",
    "            end_u = end.value//10**9\n",
    "\n",
    "            return pd.to_datetime(np.random.randint(start_u, end_u, n), unit='s')\n",
    "        \n",
    "        np.random.seed(seed=1)\n",
    "        start = data_temp.index[0]\n",
    "        end = data_temp.index[-1]\n",
    "        n = data_temp.shape[0]\n",
    "        datetime_random = random_dates(start, end, n)\n",
    "        datetime_random = datetime_random.sort_values()\n",
    "        datetime_random\n",
    "        data_temp.index = datetime_random\n",
    "        \n",
    "        if col_test==[]:\n",
    "            data_test = data_temp.copy()\n",
    "        else:\n",
    "            data_test = data_temp.loc[:, data_temp.columns.isin(col_test)]\n",
    "            \n",
    "elif datatype == \"incomplete small example data1\":\n",
    "\n",
    "    data_test = [\n",
    "        [\n",
    "            \"01:00:00\",\n",
    "            \"01:01:53\",\n",
    "            \"01:03:17\",\n",
    "            \"01:04:02\",\n",
    "            \"01:04:59\",\n",
    "            \"01:05:00\",\n",
    "            \"01:06:22\",\n",
    "            \"01:09:46\",\n",
    "            \"01:10:00\",\n",
    "            \"01:11:22\",\n",
    "            \"01:13:44\",\n",
    "            \"01:14:26\",\n",
    "            \"01:15:00\"\n",
    "        ],\n",
    "        [np.nan, 1.5, 2.2, 0.9, 3.6, np.nan, 3.3, 2.3, np.nan, 1.3, 4.3, 4.1, np.nan],\n",
    "        [1.0, np.nan, np.nan, np.nan, np.nan, 2.0, np.nan, np.nan, 3.0, np.nan, np.nan, np.nan, 4.0]\n",
    "    ]\n",
    "\n",
    "    data_test = pd.DataFrame(data_test).T\n",
    "    data_test.columns = ['ts', 'var1', 'var2']\n",
    "    data_test['var1'] = data_test['var1'].astype(float)\n",
    "    data_test['var2'] = data_test['var2'].astype(float)\n",
    "    data_test['ts'] = pd.to_datetime(data_test.ts)\n",
    "    data_test = data_test.set_index('ts')\n",
    "    \n",
    "elif datatype == \"incomplete small example data2\":\n",
    "    data_test = pd.read_csv(\n",
    "        \"../../tests/fixtures/rolling_stats_input.csv\", \n",
    "        index_col=0,\n",
    "    )\n",
    "    data_test['var1'] = pd.to_numeric(data_test['var1'], errors='coerce')\n",
    "    data_test['var2'] = pd.to_numeric(data_test['var2'], errors='coerce')\n",
    "    data_test['var1'] = data_test['var1'].astype(float)\n",
    "    data_test['var2'] = data_test['var2'].astype(float)\n",
    "    data_test.index = pd.to_datetime(data_test.index, exact=False, utc=True)\n",
    "    data_test = data_test[['var1','var2']]\n",
    "    \n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting resampling configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- default is,\n",
    "- right labeled window resampling\n",
    "- right-closed window\n",
    "- backward-looking rolling window (this happens in rolling_stats method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[\"resample\"] = {}\n",
    "\n",
    "# settings to put in configs\n",
    "configs[\"resample\"][\"interval\"] = \"1min\"\n",
    "\n",
    "# settings to hard-code for now\n",
    "configs[\"resample\"][\"label_on\"] = \"right\"\n",
    "\n",
    "fig = go.Figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_color = ['rgb(241,163,64)','rgb(153,142,195)']\n",
    "i_clr = 0\n",
    "for col in data_test.columns:\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data_test.index.values,\n",
    "        y=data_test[col].values,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=15,\n",
    "            color=list_color[i_clr]\n",
    "            ),\n",
    "        name=\"raw: {}\".format(col)\n",
    "    ))\n",
    "    i_clr+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(data, configs, method, symbol):\n",
    "\n",
    "    data = data_test.copy()\n",
    "\n",
    "    ####################################################################\n",
    "    # resampling for each statistics separately\n",
    "    i_clr=0\n",
    "\n",
    "    if method == \"asfreq_none\":\n",
    "        \n",
    "        data_resampled = data.asfreq(\n",
    "            freq=configs[\"resample\"][\"interval\"],\n",
    "            method=None\n",
    "        )\n",
    "        \n",
    "    if method == \"asfreq_bfill\":\n",
    "        \n",
    "        data_resampled = data.asfreq(\n",
    "            freq=configs[\"resample\"][\"interval\"],\n",
    "            method=\"bfill\"\n",
    "        )\n",
    "        \n",
    "    elif method == \"asfreq_ffill\":\n",
    "        \n",
    "        data_resampled = data.asfreq(\n",
    "            freq=configs[\"resample\"][\"interval\"],\n",
    "            method=\"ffill\"\n",
    "        )\n",
    "        \n",
    "    elif method == \"resample_left-labeled_first\":\n",
    "        \n",
    "        data_resampled = data.resample(\n",
    "            rule=configs[\"resample\"][\"interval\"],\n",
    "            label=\"left\",\n",
    "            closed=\"left\"\n",
    "        ).first()\n",
    "        \n",
    "    elif method == \"resample_right-labeled_last\":\n",
    "        \n",
    "        data_resampled = data.resample(\n",
    "            rule=configs[\"resample\"][\"interval\"],\n",
    "            label=\"right\",\n",
    "            closed=\"right\"\n",
    "        ).last()\n",
    "        \n",
    "    for df in [data_resampled]:\n",
    "        i_col=0\n",
    "        for col in df.columns:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df.index.values,\n",
    "                y=df[col].values,\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    symbol=symbol,\n",
    "                    color=list_color[i_col],\n",
    "                    size=14,\n",
    "                    line=dict(\n",
    "                        width=2,\n",
    "                        #color=list_color[i_col],\n",
    "                    ),\n",
    "                ),\n",
    "                name=\"resample ({}): {}\".format(method, col)\n",
    "            ))\n",
    "            i_col+=1\n",
    "    i_clr+=1\n",
    "    \n",
    "    return data_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying different resampling methods with test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled = resample_data(data_test, configs, \"asfreq_none\", \"x-dot\")\n",
    "data_resampled = resample_data(data_test, configs, \"asfreq_bfill\", \"cross-dot\")\n",
    "data_resampled = resample_data(data_test, configs, \"asfreq_ffill\", \"triangle-up-dot\")\n",
    "data_resampled = resample_data(data_test, configs, \"resample_left-labeled_first\", \"star-dot\")\n",
    "data_resampled = resample_data(data_test, configs, \"resample_right-labeled_last\", \"hash-dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.update_layout(\n",
    "    width=900,\n",
    "    height=600,\n",
    "#     title=dict(\n",
    "#         text=\"window_width = {}<br>window_increment = {}<br>window_position = {}<br>window_closing = {}\".format(\n",
    "#             configs[\"feat_stats\"][\"window_width\"],\n",
    "#             configs[\"feat_stats\"][\"window_increment\"],\n",
    "#             configs[\"feat_stats\"][\"window_position\"],\n",
    "#             configs[\"feat_stats\"][\"window_closing\"]\n",
    "#         ),\n",
    "#         x=0.025,\n",
    "#         xanchor='left',\n",
    "#         y=0.975,\n",
    "#         yanchor='top',\n",
    "#         font_size=15,\n",
    "#     ),\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        t=0,\n",
    "        b=150,\n",
    "    ),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=-0.15,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        font=dict(\n",
    "            size=10,\n",
    "            color=\"black\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    dtick=1000*60,\n",
    "    showgrid=True,\n",
    "    gridwidth=2, \n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    range=[-0.1, 5],\n",
    "    showgrid=False,\n",
    ")\n",
    "\n",
    "fig.write_html(\"./testing_data_resampling.html\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaned version for wattile implementation\n",
    "\n",
    "- so, `rolling_stats` method will take `True`/`False` argument to whether do rolling stats or not\n",
    "- testing done from this notebook is added in the `else` statement below\n",
    "- so, this is work is basically updating `rolling_stats` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resample_data(data, configs):\n",
    "\n",
    "    # reading configuration parameters.\n",
    "    # resample_label_on are hard coded for now. default is right labeled and right-closed window.\n",
    "    resample_interval = configs[\"resample_interval\"]\n",
    "    resample_label_on = \"right\"  # left, right\n",
    "\n",
    "    # resample data\n",
    "    if resample_label_on == \"left\":\n",
    "        data = data.resample(\n",
    "            rule=resample_interval, label=resample_label_on, closed=\"left\"\n",
    "        ).first()\n",
    "    elif resample_label_on == \"right\":\n",
    "        data = data.resample(\n",
    "            rule=resample_interval, label=resample_label_on, closed=\"right\"\n",
    "        ).last()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_stats(data, configs):\n",
    "\n",
    "    # reading configuration parameters.\n",
    "    # resample_label_on are hard coded for now. default is right labeled and right-closed window.\n",
    "    # window_closing and window_position are hard coded for now. default is right-closed and backward-looking window.\n",
    "    resample_interval = configs[\"resample_interval\"]\n",
    "    resample_label_on = \"right\"  # left, right\n",
    "    window_width = configs[\"feat_stats\"][\"window_width\"]\n",
    "    window_closing = \"right\"  # left, right\n",
    "    window_position = \"backward\"  # forward, center, backward\n",
    "\n",
    "    if configs[\"feat_stats\"][\"active\"]:\n",
    "\n",
    "        # seperate predictors and target\n",
    "        target = data[configs[\"target_var\"]]\n",
    "        X_data = data.drop(configs[\"target_var\"], axis=1)\n",
    "\n",
    "        # resampling for each statistics separately\n",
    "        data_resampler = X_data.resample(\n",
    "            rule=resample_interval, closed=window_closing, label=resample_label_on\n",
    "        )\n",
    "        data_resample_min = data_resampler.min().add_suffix(\"_min\")\n",
    "        data_resample_max = data_resampler.max().add_suffix(\"_max\")\n",
    "        data_resample_sum = data_resampler.sum().add_suffix(\"_sum\")\n",
    "        data_resample_count = data_resampler.count().add_suffix(\"_count\")\n",
    "\n",
    "        # setting configuration settings depending on window_position and window_closing\n",
    "        if window_position == \"backward\":\n",
    "            arg_center = False\n",
    "        elif window_position == \"center\":\n",
    "            arg_center = True\n",
    "        elif window_position == \"forward\":\n",
    "            arg_center = False\n",
    "            data_resample_min = data_resample_min[::-1]\n",
    "            data_resample_max = data_resample_max[::-1]\n",
    "            data_resample_sum = data_resample_sum[::-1]\n",
    "            data_resample_count = data_resample_count[::-1]\n",
    "            if window_closing == \"left\":\n",
    "                window_closing = \"right\"\n",
    "            elif window_closing == \"right\":\n",
    "                window_closing = \"left\"\n",
    "\n",
    "        # adding rolling window statistics: minimum\n",
    "        mins = data_resample_min.rolling(\n",
    "            window=window_width, min_periods=1, center=arg_center, closed=window_closing\n",
    "        ).min()\n",
    "\n",
    "        # adding rolling window statistics: maximum\n",
    "        maxs = data_resample_max.rolling(\n",
    "            window=window_width, min_periods=1, center=arg_center, closed=window_closing\n",
    "        ).max()\n",
    "\n",
    "        # adding rolling window statistics: sum\n",
    "        sums = data_resample_sum.rolling(\n",
    "            window=window_width, min_periods=1, center=arg_center, closed=window_closing\n",
    "        ).sum()\n",
    "\n",
    "        # adding rolling window statistics: count\n",
    "        counts = data_resample_count.rolling(\n",
    "            window=window_width, min_periods=1, center=arg_center, closed=window_closing\n",
    "        ).sum()  # this has to be sum for proper count calculation\n",
    "\n",
    "        # adding rolling window statistics: mean\n",
    "        means = sums.copy()\n",
    "        means.columns = means.columns.str.replace(\"_sum\", \"_mean\")\n",
    "        np.seterr(invalid=\"ignore\")  # supress/hide the warning\n",
    "        means.loc[:, :] = sums.values / counts.values\n",
    "\n",
    "        # combining min and max stats\n",
    "        data = pd.concat([mins, maxs, means], axis=1)\n",
    "\n",
    "        # reordering dataframe based on window_position\n",
    "        if window_position == \"forward\":\n",
    "            data = data[::-1]\n",
    "\n",
    "        # adding resampled target back to the dataframe\n",
    "        target = _resample_data(target, configs)\n",
    "        data[configs[\"target_var\"]] = target\n",
    "\n",
    "    else:\n",
    "\n",
    "        # resample data\n",
    "        data = _resample_data(data, configs)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_dataset_from_file(configs)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_for_rnn(configs, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watt",
   "language": "python",
   "name": "watt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
