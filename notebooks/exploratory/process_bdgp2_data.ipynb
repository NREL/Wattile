{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import pathlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_bdgp_data = \"../../../building-data-genome-project-2/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_weather = glob(path_to_bdgp_data + \"weather/weather.csv\")\n",
    "files_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv(files_weather[0], index_col=0)\n",
    "list_iso = []\n",
    "for datetime in df_weather.index:\n",
    "    list_iso.append(pd.Timestamp(datetime).isoformat())\n",
    "df_weather.index = list_iso\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_meter = glob(path_to_bdgp_data + \"meters/raw//*.csv\")\n",
    "files_meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_meters = []\n",
    "for file in files_meter:\n",
    "    list_meters.append(file.rsplit(\"\\\\\",1)[1].split(\".\")[0])\n",
    "    \n",
    "list_meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_region_bldgname = {}\n",
    "\n",
    "for file in files_meter:\n",
    "    df_meter = pd.read_csv(file, index_col=0)\n",
    "    \n",
    "    for region_bldgtype_bldgname in df_meter.columns:\n",
    "                \n",
    "        region = region_bldgtype_bldgname.split(\"_\")[0]\n",
    "        bldgtype_bldgname = region_bldgtype_bldgname.split(\"_\", 1)[1]\n",
    "        bldgname = region_bldgtype_bldgname.split(\"_\")[2]\n",
    "        \n",
    "        if region in dict_region_bldgname.keys():    \n",
    "            dict_region_bldgname[region].append(bldgtype_bldgname)\n",
    "        else:\n",
    "            dict_region_bldgname[region] = [bldgtype_bldgname]\n",
    "            \n",
    "for region in dict_region_bldgname.keys():\n",
    "       \n",
    "    dict_region_bldgname[region] = pd.DataFrame(dict_region_bldgname[region]).drop_duplicates().values.flatten().tolist()\n",
    "    \n",
    "dict_region_bldgname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for region in dict_region_bldgname.keys():\n",
    "    \n",
    "    print(\"### proceeing: {}\".format(region))\n",
    "    \n",
    "    for bldgname in dict_region_bldgname[region]:\n",
    "        \n",
    "        path_to_save_processed_files = \"../../data/BDGP2/\".format(bldgname)\n",
    "        pathlib.Path(path_to_save_processed_files).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        datetime_start = pd.Timestamp(year=2200, month=1, day=1, hour=0)\n",
    "        datetime_end = pd.Timestamp(year=1900, month=1, day=1, hour=0)\n",
    "        \n",
    "        #################################################################\n",
    "        # process predictors\n",
    "        #################################################################\n",
    "\n",
    "        df_predictors = pd.DataFrame()\n",
    "\n",
    "        df_weather_filtered = df_weather.loc[df_weather[\"site_id\"]==region, :].sort_index().copy()\n",
    "        df_weather_filtered = df_weather_filtered.loc[:,df_weather_filtered.columns!=\"site_id\"].copy()\n",
    "\n",
    "        df_predictors = df_predictors.join(df_weather_filtered, how=\"outer\")\n",
    "        df_predictors.index.names = ['Timestamp']\n",
    "        df_predictors.to_csv(path_to_save_processed_files+\"{}_Predictors.csv\".format(bldgname))  \n",
    "        \n",
    "        if pd.Timestamp(df_predictors.index[0]) < datetime_start:\n",
    "            datetime_start = pd.Timestamp(df_predictors.index[0])\n",
    "            \n",
    "        if pd.Timestamp(df_predictors.index[-1]) > datetime_end:\n",
    "            datetime_end = pd.Timestamp(df_predictors.index[-1])\n",
    "        \n",
    "        #################################################################\n",
    "        # process targets\n",
    "        #################################################################\n",
    "        \n",
    "        df_targets = pd.DataFrame()\n",
    "        \n",
    "        for meter in list_meters:\n",
    "            \n",
    "            df = pd.read_csv(path_to_bdgp_data + \"meters/raw/{}.csv\".format(meter), index_col=0)\n",
    "            df_bldg = df.loc[:, df.columns==\"{}_{}\".format(region, bldgname)]\n",
    "            list_iso = []\n",
    "            for datetime in df_bldg.index:\n",
    "                list_iso.append(pd.Timestamp(datetime).isoformat())\n",
    "            df_bldg.index = list_iso\n",
    "            \n",
    "            if df_bldg.shape[1] != 0:\n",
    "                df_bldg.columns = [meter]\n",
    "                df_targets = df_targets.join(df_bldg, how=\"outer\")\n",
    "                \n",
    "        df_targets.index.names = ['Timestamp']\n",
    "        df_targets.to_csv(path_to_save_processed_files+\"{}_Targets.csv\".format(bldgname))\n",
    "        \n",
    "        if pd.Timestamp(df_targets.index[0]) < datetime_start:\n",
    "            datetime_start = pd.Timestamp(df_targets.index[0])\n",
    "            \n",
    "        if pd.Timestamp(df_targets.index[-1]) > datetime_end:\n",
    "            datetime_end = pd.Timestamp(df_targets.index[-1])\n",
    "            \n",
    "        #################################################################\n",
    "        # process configs\n",
    "        #################################################################\n",
    "            \n",
    "        configs = {}\n",
    "                \n",
    "        # ---------------------------------------------------------------\n",
    "        configs[\"dates\"] = {}\n",
    "        configs[\"dates\"][\"start\"] = \"t:\"+datetime_start.isoformat()+\"-00:00\"\n",
    "        configs[\"dates\"][\"end\"] = \"t:\"+datetime_end.isoformat()+\"-00:00\"\n",
    "        \n",
    "        # ---------------------------------------------------------------\n",
    "        configs[\"predictors\"] = []\n",
    "        list_predictors = glob(path_to_save_processed_files + \"*_Predictors.csv\")\n",
    "        if len(list_predictors)==1:\n",
    "            df_predictors = pd.read_csv(list_predictors[0], index_col=0)\n",
    "            \n",
    "            for predictor in df_predictors.columns:\n",
    "                \n",
    "                content = {}\n",
    "                content[\"id\"] = predictor\n",
    "                content[\"dis\"] = predictor\n",
    "                content[\"column\"] = predictor\n",
    "                content[\"unit\"] = \"na\"      \n",
    "                configs[\"predictors\"].append(content)\n",
    "                \n",
    "        # ---------------------------------------------------------------\n",
    "        configs[\"targets\"] = []\n",
    "        list_targets = glob(path_to_save_processed_files + \"*_Targets.csv\")\n",
    "        if len(list_targets)==1:\n",
    "            df_targets = pd.read_csv(list_targets[0], index_col=0)\n",
    "            \n",
    "            for target in df_targets.columns:\n",
    "                \n",
    "                content = {}\n",
    "                content[\"id\"] = target\n",
    "                content[\"dis\"] = target\n",
    "                content[\"column\"] = target\n",
    "                content[\"unit\"] = \"na\"      \n",
    "                configs[\"targets\"].append(content)\n",
    "                \n",
    "        # ---------------------------------------------------------------\n",
    "        configs[\"files\"] = []\n",
    "        \n",
    "        content_p = {}\n",
    "        content_p[\"filename\"] = list_predictors[0].rsplit(\"\\\\\", 1)[1]\n",
    "        content_p[\"contentType\"] = \"predictors\"\n",
    "        content_p[\"start\"] = \"t:\"+ pd.Timestamp(pd.read_csv(list_predictors[0], index_col=0).index[0]).isoformat() +\"-00:00\"\n",
    "        content_p[\"end\"] = \"t:\"+ pd.Timestamp(pd.read_csv(list_predictors[0], index_col=0).index[-1]).isoformat() +\"-00:00\"\n",
    "        configs[\"files\"].append(content_p)\n",
    "        \n",
    "        content_t = {}\n",
    "        content_t[\"filename\"] = list_targets[0].rsplit(\"\\\\\", 1)[1]\n",
    "        content_t[\"contentType\"] = \"targets\"\n",
    "        content_t[\"start\"] = \"t:\"+ pd.Timestamp(pd.read_csv(list_targets[0], index_col=0).index[0]).isoformat() +\"-00:00\"\n",
    "        content_t[\"end\"] = \"t:\"+ pd.Timestamp(pd.read_csv(list_targets[0], index_col=0).index[-1]).isoformat() +\"-00:00\"\n",
    "        configs[\"files\"].append(content_t)\n",
    "                \n",
    "        with open(path_to_save_processed_files+\"{} Config.json\".format(bldgname), \"w\") as fp:\n",
    "            json.dump(configs, fp, ensure_ascii=False)\n",
    "        \n",
    "#         break\n",
    "        \n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
