{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from wattile.entry_point import init_logging, create_input_dataframe, run_model\n",
    "from wattile.data_reading import read_dataset_from_file\n",
    "from wattile.buildings_processing import prep_for_rnn, rolling_stats, pad_full_data, input_data_split\n",
    "from wattile.entry_point import run_model\n",
    "\n",
    "\n",
    "PROJECT_DIRECTORY = Path().resolve().parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "For this example, we will be using the default configs.\n",
    "Check out the docs for an explaination of each config.\n",
    "\"\"\"\n",
    "with open(PROJECT_DIRECTORY / \"wattile\" / \"configs\" / \"configs.json\", \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "\n",
    "exp_dir = PROJECT_DIRECTORY / \"notebooks\" / \"exp_dir\"\n",
    "if exp_dir.exists():\n",
    "    shutil.rmtree(exp_dir)\n",
    "exp_dir.mkdir()\n",
    "\n",
    "configs[\"exp_dir\"] = str(exp_dir)\n",
    "configs[\"data_dir\"] = str(PROJECT_DIRECTORY / \"data\")\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"incomplete small example data2\" # complete example data, incomplete example data, incomplete small example data\n",
    "incompleteness = True\n",
    "# col_test = ['Synthetic Weather Station Direct Normal Irradiance']\n",
    "col_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datatype == \"complete example data\":\n",
    "    \"\"\"\n",
    "    Firstly, we will read the raw data from the dataset. \n",
    "    Checkout the docs for an indepth explaination of necessary dataset structure.\n",
    "    \"\"\"\n",
    "    data = read_dataset_from_file(configs)\n",
    "    data\n",
    "    \n",
    "    if incompleteness == True:\n",
    "        \n",
    "        # data_temp = data.loc[\"2021-12-01\":\"2021-12-01\" :,].copy()\n",
    "        data_temp = data.copy()\n",
    "        data_temp\n",
    "\n",
    "        # adding irregular measurement intervals\n",
    "        list_cols = ['Synthetic Weather Station Dew Point Temperature', 'Synthetic Weather Station Diffuse Horizontal Irradiance', 'Synthetic Weather Station Global Horizontal Irradiance']\n",
    "        list_interval_mins = [3, 5, 7]\n",
    "        list_timeshift_mins = [0, 3, 7]\n",
    "        \n",
    "        i=0\n",
    "    \n",
    "        for col, timestep, loffset in zip(list_cols, list_interval_mins, list_timeshift_mins):\n",
    "\n",
    "            print(\"resampling and shifting column = {} with resampling timestep of {} and time-shift of {}\".format(col, timestep, loffset))\n",
    "\n",
    "            minutes = str(timestep) + \"T\"\n",
    "            loffset = str(loffset) + \"min\" \n",
    "            df_temp = data_temp[col].resample(minutes).mean().copy()\n",
    "            df_temp.index = df_temp.index + to_offset(loffset)\n",
    "            data_temp[col] = df_temp\n",
    "\n",
    "        # adding NaNs in random places\n",
    "        fraction = 0.1\n",
    "        list_index_random = data_temp.sample(frac=fraction, replace=False, random_state=1).index.tolist()\n",
    "        list_column_random = pd.DataFrame(data_temp.columns).sample(frac=fraction, replace=False, random_state=2).iloc[:,0].tolist()\n",
    "\n",
    "        i=0\n",
    "        for ind in list_index_random:\n",
    "\n",
    "            for col in list_column_random:\n",
    "\n",
    "                #print(\"replacing value in index = {} and column = {} to blank\".format(ind, col))\n",
    "                data_temp.loc[ data_temp.index==ind , data_temp.columns==col ] = np.NAN\n",
    "                \n",
    "        # adding irregular/random timestamps\n",
    "        def random_dates(start, end, n):\n",
    "\n",
    "            start_u = start.value//10**9\n",
    "            end_u = end.value//10**9\n",
    "\n",
    "            return pd.to_datetime(np.random.randint(start_u, end_u, n), unit='s')\n",
    "        \n",
    "        np.random.seed(seed=1)\n",
    "        start = data_temp.index[0]\n",
    "        end = data_temp.index[-1]\n",
    "        n = data_temp.shape[0]\n",
    "        datetime_random = random_dates(start, end, n)\n",
    "        datetime_random = datetime_random.sort_values()\n",
    "        datetime_random\n",
    "        data_temp.index = datetime_random\n",
    "        \n",
    "        if col_test==[]:\n",
    "            data_test = data_temp.copy()\n",
    "        else:\n",
    "            data_test = data_temp.loc[:, data_temp.columns.isin(col_test)]\n",
    "            \n",
    "elif datatype == \"incomplete small example data1\":\n",
    "\n",
    "    data_test = [\n",
    "        [\n",
    "            \"01:00:00\",\n",
    "            \"01:01:53\",\n",
    "            \"01:03:17\",\n",
    "            \"01:04:02\",\n",
    "            \"01:04:59\",\n",
    "            \"01:05:00\",\n",
    "            \"01:06:22\",\n",
    "            \"01:09:46\",\n",
    "            \"01:10:00\",\n",
    "            \"01:11:22\",\n",
    "            \"01:13:44\",\n",
    "            \"01:14:26\",\n",
    "            \"01:15:00\"\n",
    "        ],\n",
    "        [np.nan, 1.5, 2.2, 0.9, 3.6, np.nan, 3.3, 2.3, np.nan, 1.3, 4.3, 4.1, np.nan],\n",
    "        [1.0, np.nan, np.nan, np.nan, np.nan, 2.0, np.nan, np.nan, 3.0, np.nan, np.nan, np.nan, 4.0]\n",
    "    ]\n",
    "\n",
    "    data_test = pd.DataFrame(data_test).T\n",
    "    data_test.columns = ['ts', 'var1', 'var2']\n",
    "    data_test['var1'] = data_test['var1'].astype(float)\n",
    "    data_test['var2'] = data_test['var2'].astype(float)\n",
    "    data_test['ts'] = pd.to_datetime(data_test.ts)\n",
    "    data_test = data_test.set_index('ts')\n",
    "    \n",
    "elif datatype == \"incomplete small example data2\":\n",
    "    data_test = pd.read_csv(\n",
    "        \"C:/Users/JKIM4/Documents/GitHub/intelligentcampus-pred-analytics/tests/data/feature_extraction_input.csv\", \n",
    "        index_col=0,\n",
    "    )\n",
    "    data_test['var1'] = pd.to_numeric(data_test['var1'], errors='coerce')\n",
    "    data_test['var2'] = pd.to_numeric(data_test['var2'], errors='coerce')\n",
    "    data_test['var1'] = data_test['var1'].astype(float)\n",
    "    data_test['var2'] = data_test['var2'].astype(float)\n",
    "    data_test.index = pd.to_datetime(\n",
    "        data_test.index, \n",
    "        format=\"%Y-%m-%dT%H:%M:%S%z\", \n",
    "        exact=False, \n",
    "        utc=True,\n",
    "    )\n",
    "    \n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing rolling window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[\"feat_stats\"] = {}\n",
    "configs[\"feat_stats\"][\"window_width\"] = \"5min\"\n",
    "configs[\"feat_stats\"][\"window_increment\"] = \"1min\"\n",
    "configs[\"feat_stats\"][\"window_position\"] = \"backward\" # forward, backward, center \n",
    "# don't put it in configs\n",
    "# but mention in readme\n",
    "configs[\"feat_stats\"][\"window_closing\"] = \"left\" # left, right, neither, both\n",
    "\n",
    "# target asfreq note into readme\n",
    "# best practice: use raw data target interval for window_increment\n",
    "\n",
    "fig = go.Figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_color = ['rgb(241,163,64)','rgb(153,142,195)']\n",
    "i_clr = 0\n",
    "for col in data_test.columns:\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data_test.index.values,\n",
    "        y=data_test[col].values,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=15,\n",
    "            color=list_color[i_clr]\n",
    "            ),\n",
    "        name=\"raw: {}\".format(col)\n",
    "    ))\n",
    "    i_clr+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_stats(data_test, window_width, window_increment, window_position, window_closing):\n",
    "    \n",
    "    ####################################################################\n",
    "    # resampling for each statistics separately\n",
    "    data_resample_min = data_test.resample(rule=window_increment).agg(['min'])\n",
    "    data_resample_max = data_test.resample(rule=window_increment).agg(['max'])\n",
    "    data_resample_sum = data_test.resample(rule=window_increment).agg(['sum'])\n",
    "    data_resample_count = data_test.resample(rule=window_increment).agg(['count'])\n",
    "\n",
    "    i_clr=0\n",
    "    for df in [data_resample_min, data_resample_max, data_resample_sum, data_resample_count]:\n",
    "        i_col=0\n",
    "        for col in df.columns:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df.index.values,\n",
    "                y=df[col].values,\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    symbol='x-thin',\n",
    "                    color=list_color[i_col],\n",
    "                    size=10,\n",
    "                    line=dict(\n",
    "                        width=2,\n",
    "                        color=list_color[i_col],\n",
    "                    ),\n",
    "                ),\n",
    "                name=\"resample: {}\".format(col)\n",
    "            ))\n",
    "            i_col+=1\n",
    "            i_clr+=1\n",
    "\n",
    "    ####################################################################\n",
    "    # setting configuration settings depending on window_position and window_closing\n",
    "    if window_position == \"backward\":\n",
    "        arg_center = False\n",
    "    elif window_position == \"center\":\n",
    "        arg_center = True\n",
    "    elif window_position == \"forward\":\n",
    "        arg_center = False\n",
    "        data_resample_min = data_resample_min[::-1]\n",
    "        data_resample_max = data_resample_max[::-1]\n",
    "        data_resample_sum = data_resample_sum[::-1]\n",
    "        data_resample_count = data_resample_count[::-1]\n",
    "        if window_closing == \"left\":\n",
    "            window_closing = \"right\"\n",
    "        elif window_closing == \"right\":\n",
    "            window_closing = \"left\"\n",
    "\n",
    "    ####################################################################\n",
    "    # handling multiindex column header\n",
    "    data_resample_min.columns = data_resample_min.columns.map('_'.join)\n",
    "    data_resample_max.columns = data_resample_max.columns.map('_'.join)\n",
    "    data_resample_sum.columns = data_resample_sum.columns.map('_'.join)\n",
    "    data_resample_count.columns = data_resample_count.columns.map('_'.join)\n",
    "\n",
    "    ####################################################################    \n",
    "    # adding rolling window statistics: minimum\n",
    "    mins = (\n",
    "        data_resample_min.rolling(\n",
    "            window=window_width, \n",
    "            min_periods=1,\n",
    "            center=arg_center,\n",
    "            closed=window_closing\n",
    "        ).min()\n",
    "    )\n",
    "    # adding rolling window statistics: maximum\n",
    "    maxs = (\n",
    "        data_resample_max.rolling(\n",
    "            window=window_width, \n",
    "            min_periods=1,\n",
    "            center=arg_center,\n",
    "            closed=window_closing\n",
    "        ).max()\n",
    "    )\n",
    "    # adding rolling window statistics: sum\n",
    "    sums = (\n",
    "        data_resample_sum.rolling(\n",
    "            window=window_width, \n",
    "            min_periods=1,\n",
    "            center=arg_center,\n",
    "            closed=window_closing\n",
    "        ).sum()\n",
    "    )\n",
    "    # adding rolling window statistics: count\n",
    "    counts = (\n",
    "        data_resample_count.rolling(\n",
    "            window=window_width, \n",
    "            min_periods=1,\n",
    "            center=arg_center,\n",
    "            closed=window_closing\n",
    "        ).sum() # this has to be sum for proper count calculation\n",
    "    )\n",
    "    # adding rolling window statistics: mean\n",
    "    means = sums.copy()\n",
    "    means.columns = means.columns.str.replace(\"_sum\",\"_mean\")\n",
    "    # supress/hide the warning\n",
    "    np.seterr(invalid='ignore')\n",
    "    means.loc[:, :] = sums.values/counts.values\n",
    "    # combining min and max stats\n",
    "    data_test = pd.concat([mins, maxs, means], axis=1)  \n",
    "\n",
    "    ####################################################################\n",
    "    # reordering dataframe based on window_position\n",
    "    if (window_position == \"backward\")|(window_position == \"center\"):\n",
    "        pass\n",
    "    elif window_position == \"forward\":\n",
    "        data_test = data_test[::-1]\n",
    "\n",
    "    i_clr=0\n",
    "    for col in data_test.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=data_test.index.values,\n",
    "            y=data_test[col].values,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                color=\"rgba(255,255,255,0)\",\n",
    "                size=25,\n",
    "                line=dict(\n",
    "                    width=2,\n",
    "                ),\n",
    "            ),\n",
    "            name=\"rolling: {}\".format(col)\n",
    "        ))\n",
    "        i_clr+=1\n",
    "\n",
    "    return data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = rolling_window_stats(\n",
    "    data_test, \n",
    "    configs[\"feat_stats\"][\"window_width\"], \n",
    "    configs[\"feat_stats\"][\"window_increment\"], \n",
    "    configs[\"feat_stats\"][\"window_position\"], \n",
    "    configs[\"feat_stats\"][\"window_closing\"]\n",
    ")\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ref = pd.read_csv(\n",
    "    \"C:/Users/JKIM4/Documents/GitHub/intelligentcampus-pred-analytics/tests/data/feature_extraction_output.csv\", \n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "df_ref.index = pd.to_datetime(\n",
    "    df_ref.index, \n",
    "    format=\"%Y-%m-%dT%H:%M:%S%z\", \n",
    "    exact=False, \n",
    "    utc=False,\n",
    ")\n",
    "\n",
    "for col in df_ref.columns:\n",
    "    \n",
    "    df_ref[col] = pd.to_numeric(df_ref[col], errors='coerce')\n",
    "    df_ref[col] = df_ref[col].astype(float)\n",
    "    \n",
    "for col in df_ref.columns:\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_ref.index.values,\n",
    "        y=df_ref[col].values,\n",
    "        mode='lines+markers',\n",
    "        name=\"ref: {}\".format(col)\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=500,\n",
    "    title=dict(\n",
    "        text=\"window_width = {}<br>window_increment = {}<br>window_position = {}<br>window_closing = {}\".format(\n",
    "            configs[\"feat_stats\"][\"window_width\"],\n",
    "            configs[\"feat_stats\"][\"window_increment\"],\n",
    "            configs[\"feat_stats\"][\"window_position\"],\n",
    "            configs[\"feat_stats\"][\"window_closing\"]\n",
    "        ),\n",
    "        x=0.025,\n",
    "        xanchor='left',\n",
    "        y=0.975,\n",
    "        yanchor='top',\n",
    "        font_size=15,\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        t=90,\n",
    "        b=150,\n",
    "    ),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=-0.15,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        font=dict(\n",
    "            size=10,\n",
    "            color=\"black\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    dtick=1000*60,\n",
    "    showgrid=True,\n",
    "    gridwidth=2, \n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    range=[-0.1, 5],\n",
    "    showgrid=False,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# # The bin folder has the DLLs\n",
    "# os.environ['path'] += r';C:/Users/JKIM4/Downloads/vips-dev-w64-all-8.11.0/vips-dev-8.11/bin'\n",
    "# import pyvips\n",
    "# import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.write_image(fig, \"./fig_test.svg\")\n",
    "# # https://stackoverflow.com/questions/51450134/how-to-convert-svg-to-png-or-jpeg-in-python\n",
    "# image = pyvips.Image.thumbnail(\"./fig_test.svg\", 3000)\n",
    "# image.write_to_file(\"./fig_test.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watt",
   "language": "python",
   "name": "watt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
